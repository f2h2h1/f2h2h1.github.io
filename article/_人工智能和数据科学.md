为什么无法学习新知识了？
    不知道从哪里开始学习
        没有明确的学习路径
    理论知识记不住
    缺少实践机会
    学会了，如何证明自己学会了？
如何判断自己是否学会了某一项技能？
    特别是数学相关的？
        感觉看原理时一看就懂，实践时一做就错
如何实现一个搜索引擎？
    搜索引擎的原理
        分词（word segmentation）
        倒排索引（Inverted index）
        Lucene java
            solr
            elasticsearch
            Lucene 只是一个库，要实现具体的功能需要写代码
            Elasticsearch 和 Solr 都是基于 Lucene 的全文搜索服务器
            Elasticsearch 内置了高可用和分布式
            Solr 需要 ZooKeeper 才能实现高可用和分布式
        sphinx c
        mysql的全文搜索
        BM25算法
        Sparse（稀疏表示 / 稀疏检索）
    nutch+solr+Hadoop+Hbase
    搜索引擎的测试数据
        中文
            THUCNews （清华大学中文文本分类数据集）
            http://thuctc.thunlp.org/?spm=a2ty_o01.29997173.0.0.317ac921UEaPYN
        英文
            es 提供的测试数据集
            https://www.elastic.co/docs/manage-data/ingest/sample-data
        自己写个爬虫去爬豆瓣的资料
        从那些 刮削器 里获得数据
    自己在数据库中实现一个倒排索引？
    和数据库直接用like对比
    SQLite的全文搜索
        SQLite 实现全文搜索主要依赖其 FTS（Full-Text Search）模块 
        SQLite 的 FTS 功能默认可能未启用，需在编译时添加相关参数
        SQLite 内置分词器不支持中文，需使用扩展（如 ICU 或第三方分词器）
            simple 是一个支持中文和拼音的 sqlite3 fts5 拓展 https://github.com/wangfenjin/simple
    混合搜索（Hybrid Search）
        向量搜索（semantic/Dense vector/ Embedding Search）
        全文搜索（Sparse / BM25 / 倒排索引）
        混合搜索是把不同类型的信息检索方法组合在一起，以提高搜索结果的相关性和覆盖面。
        常见做法是把基于向量的语义搜索（semantic/embedding search）和
        基于关键词或稀疏表示的传统检索（keyword / BM25 /倒排索引）结合起来。
        这样既保留关键词检索在精确匹配与稀疏信号（比如专有名词、精确术语、元数据）的优势，
        又利用向量搜索捕捉语义相似性、同义词和上下文信息的能力。
搜索算法
    无信息搜索
        深度优先
        广度优先
    启发式搜索
        IDS 和 IDDFS
        贪婪最佳优先算法
        Dijkstra算法(狄克斯特拉算法)
        A*寻路算法
    对抗搜索
        极小极大值算法
        α-β剪枝
        蒙特卡罗树搜索算法
数学
    初等数学
        基础的数学
            数的概念
            数的顺序
            数的大小关系
            数的进制
            运算符
                加法
                减法
                乘法
                除法
                    地板除
                    有余数的除法
                    有小数的除法
                    分数
                取余
                阶乘
                指数
                对数
                运算符优先级
                运算的规律
                    交换律
                    结合律
            分数
                分数的性质
                分数的运算规律
            小数
                有限小数
                无限小数
                    无限循环小数
                    无限不循环小数
            单位
                数量单位
                计量单位
                    基本单位
                        秒     时间
                        米     长度
                        千克   质量
                        开尔文 温度
                        安培   电流强度
                        坎德拉 发光强度
                        摩尔   物质的量
                    导出单位
                        频率
                        力
                        压强
                        热量
                        功率
                        电荷量
                        电阻
                        ...
                    组合单位
                        面积
                        体积
                        速度
                        ...
                货币单位
                    主要的货币
                        人民币
                        港元
                        日元
                        英镑
                        美元
                        卢比
                        欧元
                        法郎
                            瑞士法郎
                            非洲法郎
                            太平洋法郎
                    币值单位
                        元
                        角
                        分
                        厘
        初等数论
            自然数
            正数
            负数
            整数
            实数
            有理数
            无理数
            素数（质数）
            因数
            合数
        初等代数
            比例
            方程
                一元一次
                一元二次
            抽象的函数
        几何
            平面几何
                点
                线
                    数轴
                    直线
                    射线
                    线段
                面
                    二维坐标系统
                        二维的笛卡尔坐标系 平面直角坐标系
                        极坐标系
                        坐标系的变换
                    角
                    图形
                        不规则
                        规则 （可以使用简单的函数表示的？）
                            三角形
                                特殊的三角形
                                    直角三角形
                                    等腰三角形
                                        等边三角形
                            矩形
                                特殊的矩形
                                    梯形
                                        等腰梯形
                                    平行四边形
                                        长方形
                                            正方形
                            多边形
                                特殊的多变形
                                    正x边形
                            圆
                                直线的斜角和斜率
                                普通的圆
                                椭圆
                                弓形
                                扇形
                                双曲线
                                抛物线
                平面向量
            立体几何
                三维坐标系统
                    三维的笛卡尔坐标系 空间直角坐标系
                    圆柱坐标系
                    球坐标系
                长方体
                立方体
                圆柱体
                球
                空间向量
            三角学
        概率论和统计学
            随机变量
            数学期望
        暂时不会分类的
            集合
            逻辑
            不等式
            数列
            排列组合
            导数
            数学选修3-4 对称与群
        微积分之后的数学都可以叫做高等数学了
    微积分
    线性代数
    概率论
    数理统计
    离散数学
        数理逻辑
        集合论
        组合数学
        图论
        运筹学
        博弈论
        信息论
    最优化
    数学的历史
        三次危机
        微积分之前
        微积分之后
    黄申
        智能聊天机器人：核心技术与算法
        大数据架构和算法实现之路：电商系统的技术实战
        大数据架构商业之路：从业务需求到技术方案
        程序员的数学基础课 从理论到Python实践
从零开始学习数学建模
    我总想找到一种方法来应对所有类型的算法面试题
    或者说我总想找到一种方法来应对所有考试时遇到的数学题
    或者说我总想找到一种方法来应对所有考试时遇到的问题
    我们为什么可以把题目归类为一类相似的问题？
    题型的数量是不是可以无限地增加？
    数学建模需要哪些前置的知识？
    第1步	识别问题
    第2步	做出假设
        a.识别变量并对变量进行分类
        b.识别变量和子模型之间的相互关系
    第3步	求解模型
    第4步	验证模型
        a.表述了问题吗？
        b.在通常意义下它有意义吗？
        c.用实际数据来验证该模型
    第5步	实施模型
    第6步	验证模型
    数学建模 https://book.douban.com/subject/1231271/
    数学建模方法与分析 https://book.douban.com/subject/1392709/
    感觉数学建模的那些算法和机器学习的十分相似，可能就是同一套。。。
    算法
        预测
        分类
        最优化
    经典的机器学习算法
        线性回归算法 (Linear Regression)
        支持向量机算法 (Support Vector Machine, SVM)
        最近邻居/k-近邻算法 (K-Nearest Neighbors, KNN)
        逻辑回归算法 (Logistic Regression)
        决策树算法 (Decision Tree)
        k-平均算法 (K-Means)
        随机森林算法 (Random Forest)
        朴素贝叶斯算法 (Naive Bayes)
        降维算法 (Dimensional Reduction)
        梯度增强算法 (Gradient Boosting)
        遗传算法（Genetic Algorithm, GA）
        模拟退火（Simulated annealing, SA）
        蒙特卡罗方法（Monte Carlo method）
        马尔可夫链（Markov chain）
        隐马尔可夫模型（Hidden Markov Model, HMM）
    各种 人工智能/机器学习/深度学习/数据分析/数据挖掘 的模型
    这些模型各自的应用场景和优缺点
        这些模型有哪些经典的应用
    这些模型所对应的算法和算法对应的数学原理
        这些数学理论如何和机器学习的模型联系起来
        这些机器学习的模型如何和数学理论联系起来
        就是要双向连接
    这些模型在不同条件下的分类
        例如 有没有监督 训练样本有没有标签 是不是线性模型 用于分类还是用于预测 是不是概率模型 是不是生成式模型 是单模型还是集成模型
    这些 模型/算法 的发展历史
        例如 由谁提出的，在哪篇论文最先提到，有哪些变体
leetcode做题的一般套路
    要把问题抽象成数学问题
        要抽象成类似这样的函数
            答案=解答(输入)
        从写代码的角度大概就是三步
            读取和解释输入
            处理输入
            格式化输出
        多数 leetcode 的题目都会自动处理好第一步和第三步
        实际面试时可能依然要自己处理输入和输出
            代码随想录里把
                不需要处理输入输出的称为 核心模式
                需要处理输入输出的称为 ACM模式
                https://github.com/youngyangyang04/leetcode-master/blob/master/problems/%E5%89%8D%E5%BA%8F/ACM%E6%A8%A1%E5%BC%8F.md
    要准确地理解问题，然后选择正确的数据结构和算法
        理解 哪些是 已知 哪些是 未知 ，题目的目标是什么？要求哪个未知变量？
        列出 已知变量 和 未知变量
        列出 各个变量 之间的关系
    先学好理论再去做题
    如果一道题一直没思路就直接看答案
算法思想
    主要的算法思想 (algorithmic paradigm)
        穷举 (exhaustion) Brute 暴力
        递归 (recursion)
        贪心 (greedy)
        分治 (divide and conquer)
        剪支和搜索 (prune and search)
        回溯 (backtracking)
        动态规划 (Dynamic programming, DP)
            动态规划 约等于 深度优先搜索 + 回溯
        分支界限 (Branch and bound, BB B&B BnB)
            分支界限 约等于 广度优先搜索 + 回溯
    算法思想之所被称为思想是因为算法思想可以应用到不同的数据结构里
    一个具体的算法肯定是基于至少一个具体的数据结构
    一种数据结构通常至少会有三种算法
        遍历 搜索 排序
    简单但不严谨的比喻
        数据结构 是 食材
        算法 是 菜谱
        算法思想 是 烹饪方式
    为什么穷举也可以算作一种算法思想？
    迭代，递归，循环的区别
        循环 loop
            循环 强调 重复同一个操作
        迭代 iteration
            迭代 强调 下一次的输入会依赖上一次的输出
        递归 recursion
            递归 强调 函数自己调用自己
        递推是什么？
            递推没有对应的英文，通常用递归的英文 recursion
            递推可能是指递归也可能是指迭代
            简中网的文章大多会强调递推是自底向上，递归是自定向下
                从个人写代码的感受而言，递推和递归确实可以分成两种不同的情况
    算法思想 通常是来自数学上相关的学科 例如 运筹学 最优化 组合数学 这类
    有多种方法可以对算法进行分类
        根据应用分：
            按照算法的应用领域，可以分为
            基本算法，数据结构相关算法，几何算法，图论算法，规划算法，数值分析算法，加密解密算法，排序算法，查找算法，并行算法，数值算法……
        根据确定性分：
            确定性算法：有限时间内完成，得到结果唯一。
            非确定性算法：有限时间内完成，得到结果不唯一，存在多值性。
        根据算法的思路分：
            递归算法，穷举算法，贪婪算法，分治算法，动态规划算法等。
动态规划(Dynamic programming, DP)
    递归
    深度优先搜索
    贪心
    回溯和剪支
        回溯算法在尝试和回退中穷举所有可能的解，并通过剪枝避免不必要的搜索分支
    记忆化递归
    制表
        这个和滚动数组有什么联系？
    一些语境下，
        记忆（Memoization） 和 制表（Tabulation） 会被区分开来，
        把 记忆 称为 记忆化递归 或 备忘录；把 制表 称为 动态规划。
        或者把 记忆 和 制表 统称称为广义动态规划，把 制表 称为狭义动态规划。
    制表 可以看作是 优化后的 记忆
    通常情况下使用 记忆 需要更多的内存，
        在力扣刷题时，一些题目有内存限制，使用 记忆 可能会无法通过，
        但存在一些问题 制表 是无法解决的，依然需要使用 记忆 的方法
    例题
        斐波那契数列
            // 普通递归
            function fibonacci_1($n)
            {
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                return fibonacci_1($n - 1) + fibonacci_1($n - 2);
            }

            // 记忆化递归 备忘录
            function fibonacci_2($n)
            {
                static $ret = [];
                if (isset($ret[$n])) {
                    return $ret[$n];
                }
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                return fibonacci_2($n - 1) + fibonacci_2($n - 2);
            }

            // 动态规划
            function fibonacci_3($n)
            {
                $ret = new SplFixedArray($n + 1);
                $ret[0] = 0;
                $ret[1] = 1; // 边界条件
                for ($i = 2; $i <= $n; $i++) {
                    $ret[$i] = $ret[$i - 1] + $ret[$i - 2]; // 状态转移方程
                }
                return $ret[$n]; // 返回最优解
            }

            // 基于动态规划继续优化1 滚动数组
            function fibonacci_3($n)
            {
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                $ret = new SplFixedArray(3);
                $ret[0] = 0;
                $ret[1] = 1;
                $n = $n - 1;
                do {
                    $ret[2] = $ret[1] + $ret[0];
                    $ret[0] = $ret[1];
                    $ret[1] = $ret[2];
                    $n--;
                } while ($n > 0);
                return $ret[2];
            }
            // 基于动态规划继续优化2
            function fibonacci_3($n)
            {
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                $a = 0;
                $b = 1;
                $n = $n - 1;
                do {
                    $ret = $b + $a;
                    $a = $b;
                    $b = $ret;
                    $n--;
                } while ($n > 0);
                return $ret;
            }
        背包问题 （Knapsack Problem）
            题干
                假设有一个背包，
                能够承载的最大重量为 W，
                同时有 n 个物品，每个物品 i 具有一个重量 wi​ 和一个价值 vi​。
                目标是选择一些物品放入背包中，使得所选物品的总重量不超过 W，并且总价值最大化。
            分类
                0-1背包
                    如果限定每种物品只能选择0个或1个，则问题称为0-1背包问题
                完全背包/无界背包问题
                    如果不限定每种物品的数量，则问题称为无界背包问题
                多重背包/有界背包问题
                    如果限定物品j最多只能选择bj个，则问题称为有界背包问题
    先有循环，后有表格，表格就是两层循环的数组展开后的结果
    参考
        https://oi-wiki.org/dp/
        https://github.com/labuladong/fucking-algorithm/blob/master/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%B3%BB%E5%88%97/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%AF%A6%E8%A7%A3%E8%BF%9B%E9%98%B6.md
        https://mp.weixin.qq.com/s/1V3aHVonWBEXlNUvK3S28w
数据分析/机器学习/数据挖掘/数据科学/大数据
    名词
        artificial intelligence AI
        big data 大数据
        statistic 统计
        statistical analysis 统计分析
        Data Analysis 数据分析
        Data Mining 数据挖掘
        Machine Learning 机器学习
        data scientist 数据科学
        data source 数据源
        Data mesh 数据网络
        OLTP
            online transaction processing
            在线 事务 处理
        OLAP
            online analytical processing
            在线 分析 处理
        HTAP
            Hybrid Transaction and Analytical Process
            混合 事务 和 分析 处理
        DB
            Data Base
            数据 库
        DL
            Data Lake
            数据 湖
        DW / DWH
            Data Warehouse
            数据 仓库
        DM
            Data Mart
            数据 集市
        KB
            Knowledge Base
            知识 库
        ETL
            Extract-Transform-Load
            抽取-转换-加载
        ELT
            Extract-load-transform
            抽取-加载-转换
        DSS
            Decision Support System
            决策 支持 系统
        BI
            Business Intelligence
            商业 智能
        data viz/vis
            Data visualization
            数据 可视化
        data lakehouse
            数据 湖仓一体
        data architecture
            数据 架构
    数据分析 使用 统计学 的方法 从已有的数据中 验证预设的假设或回答特定的业务问题
    机器学习 把已有的数据作为训练集(Training Set)，建立模型，用模型处理新的数据
    数据挖掘 使用 统计学 和 机器学习 的方法 从已有的数据中 发现 关联 或 趋势
    大数据
        大数据通常是指对大量的数据进行数据分析或数据挖掘
        只要数据量足够大就可以自称大数据
        大数据往往需要用到这些工具
            Hadoop系列
                hive hadoop MapReduce Lucene NDFS/HDFS Hbase Nutch
                MapReduce 最早是由 Google 公司研究提出的一种面向大规模数据处理的并行计算模型和方法。 
                Google 公司设计 MapReduce 的初衷主要是为了解决其搜索引擎中大规模网页数据的并行处理问题。
                Hadoop MapReduce 是 MapReduce 的开源 Java 实现
                一般语境下的 MapReduce 就是指 Hadoop MapReduce
            google
                BigTable GFS
            流式处理框架
                ApacheSpark ApacheFlink ApacheSamza ApacheStorm
            Google 的三篇论文
                《Google-File-System》
                    一个面向大规模数据密集型应用的、可伸缩的分布式文件系统
                    在 2003 年 10 月 19-22 日于美国纽约博尔德举行的第 19 届 ACM SIGOPS 操作系统原理研讨会（SOSP）上发表
                《Google-MapReduce》
                    一种处理和生成超大数据集的分布式计算模型
                    在 2004 年 12 月 6-8 日于美国旧金山举行的第 6 届 USENIX 操作系统设计与实现研讨会（OSDI）上发表
                《Google-BigTable》
                    一个用来处理海量数据的分布式、结构化数据存储系统
                    在 2006 年 10 月 22-25 日于美国西雅图举行的第 7 届 USENIX 操作系统设计与实现研讨会（OSDI）上发表
    流处理和批处理
    数据平台
        数据管理
            数据采集
            数据存储
        数据分析（Data Analysis）
            数据统计/统计分析（狭义的数据分析）
            数据挖掘（机器学习）
        数据应用
            推荐
            广告
            数据可视化
    统计是总结过去，概率是预测未来，通过统计过去来预测未来？
    数据分析 可以由业务人员独立完成
    机器学习 和 数据挖掘 通常由it主导
    文档型数据库和关系型数据库本质上有些什么区别？文档型数据库出现的背景？
    列数据库和关系型数据库本质上有些什么区别？
    Symbolic AI 符号AI
    Explainable AI，XAI 可解释AI
    Neuro-symbolic AI 混合式神经-符号AI
    weak AI 弱AI
    strong AI 强AI
    artificial general intelligence，AGI 通用人工智能
    traditional AI 传统AI
        predictive AI 预测式AI
    generative AI  GenAI 生成式AI
    AI Generated Content AIGC AI生成内容
    可能用到的语言或工具
        Python R Julia Fortran SQL
        Spyder Jupyter RStudio
        Excel Octave MATLAB Mathematica SAS SPSS stata
        PowerQuery
            excel 2010 和 2013 pq 可以作为免费的加载项
            excel 2016 pq就内置在 excel 了
            pq 也可以用在免费的 Power BI Desktop 里
    相关的职业
        数据科学家（Data scientist）
            数据科学家分析复杂的数字数据，帮助企业做出决策。
            他们利用数据科学培训和先进的分析技术，包括机器学习和预测建模，发掘数据中隐藏的洞察分析。
        数据分析师（Data analyst）
            数据分析师将数据转化为信息，将信息转化为洞察力。
            他们使用统计方法从数据集中分析和提取有意义的趋势，通常是为了为业务策略和决策提供信息。
        数据工程师（Data engineer）
            数据工程师负责准备、处理和管理大数据基础设施和工具。
            还在组织内开发、维护、测试和评估数据解决方案，经常处理大量数据集来协助分析项目。
        机器学习工程师（Machine learning engineer）
            机器学习工程师专注于设计和实施机器学习应用。
            他们开发复杂的算法，可以从数据中学习并进行预测。
        商业智能分析师（Business intelligence analyst）
            商业智能 (BI) 分析师通过分析数据得出切实可行的洞察，帮助企业做出数据驱动的明智决策。
            他们通常使用 BI 工具将数据转换为易于理解的报告和可视化图表，以供业务利益相关者查看。
        数据可视化专家（Data visualization specialist）
            这些专家专注于数据的可视化表示。
            他们创建数据可视化，通过将数据置于可视化环境中来帮助最终用户了解数据的重要性。
        数据构架师（Data architect）
            数据构架师设计、创建、部署和管理组织的数据架构。
            他们定义不同数据实体和 IT 系统如何存储、使用、集成和管理数据。
    机器学习中算法/模型的分类方式
        任务类型
            分类 预测 最优化
        学习类型
            有监督 半监督 无监督 迁移学习 强化学习
        模型结构
            线性模型 非线性模型 集成模型
人工智能
    概述
        是什么
            用机器模拟人脑
        能做什么
            理想状态下，人能做什么，ai就能做什么
        有哪些流派
            符号主义（Symbolists）
            联结主义（Connectionists）
            行为主义（Behaviorism）
    发展历史
        GOFAI -> 经典的机器学习 -> 神经网络 -> 深度学习 -> 大语言模型
        浪潮 和 寒冬
    数学基础
        初等数学
        四门基础
            微积分 线性代数 概率论 数理统计
        离散数学
            数理逻辑 集合论 组合数学 图论 运筹学 博弈论 信息论
        最优化
        数学建模
    计算机基础
        理论计算机科学
        408全家桶
            数据结构 计算机组成原理 操作系统 计算机网络
        数据库
        前端三件套
        软件工程
        常用的工具
    经典的机器学习
        五大流派
            符号主义（Symbolists）
            联结主义（Connectionists）
            贝叶斯派（Bayesians）
            进化主义（Evolutionists）
            类推主义（Analogizers）
            符号主义和联结主义和人工智能中的分类是一样的
            人工智能中的行为主义似乎没有什么存在感
            贝叶斯 进化主义 类推主义 在人工智能的流派中好像没有对应的分类
        GOFAI
            1985年，约翰·豪格兰在他的书《 人工智能：非常的想法 》中探讨了人工智能研究的哲学含义，
            将符号人工智能命名为GOFAI（Good Old-Fashioned Artificial Intelligence，指的是“有效的老式人工智能）。
            在机器人学领域 ，类似的术语是GOFR （“有效的老式机器人学”）。
            https://en.wikipedia.org/wiki/GOFAI
            GOFAI 约等于 符号主义
                知识表示	一阶谓词逻辑、语义网络、框架、脚本	用形式化的符号和结构来描述世界
                推理与搜索	A*搜索、极小化极大算法、归结原理	通过操纵符号来推导新知识、找到解决方案
                专家系统（产生式规则+推理引擎）
            GOFAI 通产包含 决策树 和 搜索算法（启发式搜索，对抗搜索）
            GOFAI 需要 离散数学
        经典的机器学习
            经典的机器学习 约等于 需要统计和概率的算法
            支持向量机 (Support Vector Machine, SVM)
                在深度学习出流行之前，最流行的是支持向量机
            经典的机器学习 需要 统计学 和 概率论
        对于模型的分类，不同的标准会有不同的分类，就像对算法的分类一样
        两条路线
            自顶向下 从应用到原理
            自底向上 从原理到应用
        如何选择机器学习的算法
            https://learn.microsoft.com/zh-cn/azure/machine-learning/how-to-select-algorithms?view=azureml-api-1
            https://zhuanlan.zhihu.com/p/345855210
            https://scikit-learn.org/stable/machine_learning_map.html
        深度学习与机器学习 https://learn.microsoft.com/zh-cn/azure/machine-learning/concept-deep-learning-vs-machine-learning?view=azureml-api-2&viewFallbackFrom=azureml-api-1&WT.mc_id=docs-article-lazzeri
    神经网络（neural network）
        神经网络在多数情况下可以归类到 经典的机器学习
        但神经网络是深度学习的基础，值得特意学习
    深度学习（Deep Learning）
    大语言模型（Large Language Model, LLM）
        自然语义处理 (Natural Language Processing, NLP)
        提示工程（Prompt Engineering）
            提示词模板
                背景介绍
                角色设定
                    明确角色
                    角色赋能
                具体任务
                    任务指令
                        任务步骤
                    约束条件
                输出格式
            分隔符
            ###
            ===
            选择哪种特殊字符并不重要，关键是这些字符足够独特，使得模型能将其识别为分隔符，而非常规标点符号
            微软的教程 提示工程技术 https://learn.microsoft.com/zh-cn/azure/ai-foundry/openai/concepts/prompt-engineering
        上下文工程（Context Engineering）
        提示链 (prompt chaining)
            提示链通过多轮对话，引导 LLM “思考” 方向，让 LLM 从简单任务开始，沿着设计好的“思考”方向逐步完成一个复杂推理
        思维链 (Chain of thought, CoT)
        AI Agent/bot/Generative AI/上下文窗口/微调/RAG/MOE
            微调（Fine-Tuning，FT）是再训练一次并加入新数据
            rag是在上下文或提示词里加入新数据
                rag 就是 知识库
                Retrieval-Augmented Generation
                检索增强生成
            AI Agent 就是 bot
                提示工程 是 Agent
                rag 是 Agent
            插件 (plugins) 就是 调用外部api
                在 工作流 里会用到 插件
            工作流 (workflow) 就是 字面意思
                和 cicd 里的工作流是一样的，只是过程中有大模型的参与
                参考一下腾讯的 混元 元宝 元器
            Function Call
            MCP（Model Context Protocol）
                MCP 是由 Anthropic 公司（Claude 模型） 推出的一个协议，
                它通过提供一种标准化的接口，LLM 应用可以访问外部信息、工具和资源。
                它相当于大模型的”HTTP协议”。
                    HTTP协议：使浏览器与服务器 交互标准化
                    MCP：使大模型与外部服务 交互标准化
            A2A（Agent2Agent）
            AG-UI（Agent-User Interaction Protocol，智能体用户交互协议）
                MCP协议——解决AI Agent和外部工具交互问题
                A2A协议——解决Agent间通信问题
                AG-UI协议——解决AI Agent与前端应用之间的交互标准化问题
            多Agent系统（Multi-Agent System, MAS）
            MOE
                Mixed Expert Models
                混合专家模型
            上下文（context）
                上下文窗口（context window）
                    这是模型在生成每个新token时实际参考的前面内容的范围
                上下文长度（context length）
                    它限制了模型一次性交互中能够处理的最大token数量
                    这是指模型单次可以处理的最大输入序列长度，通常以token数表示。
                    换句话说，这是模型可以同时“看到”的内容的最大数量。
                Context Length是一个静态的上限，涵盖了整个输入和输出过程中的所有token；
                Context Window则是一个动态的范围，每次生成token时模型实际参考的上下文。
                例子
                    假设一个模型的Context Length是2048，
                    你输入了一段包含1500个token的文本（prompt），
                    那么模型生成的响应最多只能有548个token（1500输入 + 548输出 = 2048总长度）。
                    如果这个模型的 Context Window是512 token，
                    那么在生成第513个token时，模型只能参考前面的512个token，而不是全部2048个token。
            向量库(Vector Database)
            参数（Parameters）
                权重参数（Weights）
                偏置参数（Biases）
                嵌入参数（Embeddings） EMB
            预训练（Pre-training）
            注意力机制（Attention Mechanism）
                自注意力机制（Self Attention Mechanism）
            ReAct (Reasoning and Acting) 推理和执行
            LangChain 和 LangGraph 和 langsmith
            n8n 和 Dify 和 coze 和 ComfyUI 和 Flowise 和 AutoGen 这类型的工具似乎还有很多
        满血版>满血版量化>蒸馏版>量化版(蒸馏量化版)
            满血就是没经过改动的
            量化就是可以运行在内存里的
            蒸馏(distill)就是阉割版
            量化版，一般语境下的量化版就是蒸馏量化版，就是可以运行在内存里的蒸馏版
            ollama 下载的都是量化版
            满血或蒸馏版
                显存 大于 模型的尺寸
            量化版
                显存+内存 大于 模型的尺寸
            满血 (full-powered/full-blooded/Full Version)
            模型压缩 (Model Compression)
                模型量化 (Model Quantization)
                模型蒸馏 (Model Distillation)
                模型裁剪 (Model Pruning)
                模型稀疏化 (Model Sparsity)
        模型权重
            浮点数据类型在IEEE 754-2019(2008)标准中进行了详细的定义，
            定义了不同精度的浮点数格式，如 binary16、binary32、binary64
            FP8 E4M3
                1标志位 4基数 3尾数
            FP8 E5M2
                1标志位 5基数 2尾数
                这两个也是由英伟达提出的
            binary16
                FP16
                floating point 16
                半精度浮点
                1标志位 5基数 10尾数
            brain floating point
                BFP16 BF16 bfloat16
                由Google Brain开发的，所以这个brain应该是Google Brain的第二个单词
                1标志位 8基数 7尾数
            TF32
                TensorFlow-32
                英伟达提出的代替FP32的单精度浮点格式
                19位大小
                1标志位 8基数 10尾数
            binary32
                FP32
                floating point 32
                单精度浮点
                1标志位 8基数 23尾数
            binary64
                FP64
                floating point 64
                双精度浮点
                1标志位 11基数 52尾数
            模型的训练一般用 fp32 tf32 bf16 fp16
            如果模型是 fp32 那么显存就需要模型大小的4倍，例如 70b 就需要 70*4= 280g 显存
            如果模型是 tf32 那么显存就需要模型大小的4倍，例如 70b 就需要 70*4= 280g 显存
                tf32 是引入的一种计算格式，主要用于加速FP32运算，但数据存储仍以FP32格式进行。
            如果模型是 bf16 那么显存就需要模型大小的2倍，例如 70b 就需要 70*2= 140g 显存
            如果模型是 fp16 那么显存就需要模型大小的2倍，例如 70b 就需要 70*2= 140g 显存
            如果模型是 fp8 那么显存就需要模型大小的1倍，例如 70b 就需要 70*1= 70g 显存
            如果模型是 int8 那么显存就需要模型大小的1倍，例如 70b 就需要 70*1= 70g 显存
            如果模型是 int4 那么显存就需要模型大小的0.5倍，例如 70b 就需要 70*0.5= 35g 显存
            通常会多预留一些显存，例如 28g 就用 30g显存，14g 就用 16g显存
            还有更复杂的混合精度
                fp8 和 int8 有什么区别？
                FP8 E4M3 和 FP8 E5M2 有什么区别？
                bf16 和 fb16 有什么区别？
                以我当前的水平，正确地理解这些区别似乎有一点困难
                只能简单但不严谨地理解为 没有区别
            32b的排名也很高，是因为参与排名的是原版
                平时在电脑部署的，是 4int 或 8int 的量化版
                要运行原版至少需要一张80g显存的显卡，消费级的显卡暂时还没有那么大的显存
                8int 32g
                4int 16g
            满血的deepseek R1一般是指FP8、671B权重的版本
                载入模型大概需要 671g显存，再加上一些余量，大概需要750g显存，
                国内实践一般用800g显存，大概就是10张80g的显卡
                FP8 仅能被英伟达新型GPU支持，国内会用fp16或BF16模拟，但会大大增加需要的显存
                用 fp8 的叫做原生满血
                用 fp16 的叫做转译满血
                    转译版理论上和原版一样的，但实践中往往会比不上原版，和原版的差距主要体验在转译团队的水平上
                用 int8 的叫做量化满血
                    美团有一个号称无损的int8量化版
                    https://tech.meituan.com/2025/03/07/meituan-int8-deepseek-r1.html
        那些生成图片，生成视频的模型和LLM有什么关系？
        chat模型 和 embedding模型 有什么区别？
        模态（modal）
            输入或输出的类型，例如 文本 文档 图片 视频 音频
            多模态（multi modal） 可以接收多种输入类型或可以输出多种类型
            多模态大语言模型 或者简称 多模态模型
                MLLM
                MM-LLM
                multi modal large language model
            GPT-4o，“o”代表 Omni（全能），就是表示支持多种类型的输入和输出
        局限性
            幻觉
            偏差
        什么是 多轮改写（QueryRewrite）
        什么是 重排 （rerank）
    著名的公司
        ai 四巨头
            openai 谷歌 Anthropic xai
            Anthropic 就是那个 Claude
            Anthropic 是由 openai 前员工创立的
            xai 就是 马斯克 那个 Grok
            DeepMind 就是做 AlphaGo 那个，现在是 谷歌的全资子公司
        国内的
            幻方量化/深度求索
            百度 阿里 腾讯 字节 华为 科大讯飞 月之暗面 智谱 MiniMax 太多了，几乎所有公司都有大模型
            四小龙
                商汤、旷视、云从、依图
            五虎？
                四小龙 + ？
    热门的大模型
        gpt 2022
        deepseek 2024
        Claude
        Grok
        Gemini
        gemma 谷歌的，Gemma是谷歌基于Gemini技术打造的轻量级模型系列
        LLaMA mate
        Phi 微软的
        BLOOM 来自法国的，也是开源的
        Mistral 来自法国的，也是开源的
        通义千问
        文心一言
        豆包 字节
        kimi 月之暗面
        混元
        星火 科大讯飞
        GLM(General Language Model) ZAI（智谱AI）
        大模型的排行榜
            https://github.com/jeinlee1991/chinese-llm-benchmark
            https://www.superclueai.com/
            https://super.gluebenchmark.com/leaderboard
            https://lmarena.ai/leaderboard
            https://cevalbenchmark.com/static/leaderboard_zh.html
            https://llm-stats.com/
            https://model.aibase.com/zh/leaderboard/text-generation
    应用
        文本
            生成文本 对话
        视频
            生成视频 视频换脸
        音频
            语音 音乐
        图片
            Midjourney
            DALL-E 3
            gpt4o
            文心一格
            Microsoft Designer
                DALL-E 3
            Adobe Firefly
                DALL-E 3 + Midjourney
        AI代码生成
            cursor
            Trae 也是来自字节
            MarsCode (豆包)
            文心快码
            GitHub Copilot
            通义灵码
            代码小浣熊 商汤
            CodeWhisperer 亚马逊
            CodeGeeX 智谱
            AI 编程工具一般有三种产品形态
                IDE 插件
                独立的 IDE。插件受制于宿主软件，有些公司不甘束缚，就开始做专门的 AI 编程 IDE，
                    比如 Cursor、亚马逊的 Kiro、谷歌的 AntiGravity。
                终端。还有一些公司，专门做基于终端（也就是命令行）的工具，
                    比如 Claude Code、Codex CLI、Gemini CLI。
                    命令行工具还可以用在 ci/cd 里
            vscode中的插件
                Roo Code https://github.com/RooCodeInc/Roo-Code
                continue https://github.com/continuedev/continue
                GitHub Copilot https://github.com/microsoft/vscode-copilot-chat
    有影响力的人
        AI 三巨头
            Geoffrey Hinton：中文名是 杰弗里·辛顿
                玻尔兹曼机
                    他与特里·塞杰诺夫斯基共同提出，是早期的一种随机递归神经网络，为后来的深度信念网络提供了基础。
                反向传播算法
                    虽然反向传播的思想并非辛顿首创，
                    但他在1986年与大卫·鲁梅尔哈特、罗纳德·威廉姆斯合著的论文《通过反向传播错误学习内部表征》中，
                    独立且清晰地阐述了这一算法，并证明了其有效性。
                    这为训练多层（深度）神经网络提供了可行的、高效的数学工具。
                深度信念网络
                    在2006年，辛顿及其团队发表了《一种深度信念网络的快速学习算法》
                    工作打破了当时训练深度网络的僵局，解决多层网络训练困难的问题。
                ImageNet竞赛与AlexNet的胜利
                    AlexNet以压倒性优势夺冠，震惊了整个计算机视觉界。
                    它向世界无可辩驳地证明了深度学习的巨大威力，
                    标志着计算机视觉乃至整个人工智能领域进入了一个新时代。
            Yann LeCun：中文名是 杨立昆
                卷积神经网络的发明
                DjVu图像压缩技术
                推动AI研究的开放与工业化
                    作为Facebook（现Meta）首席AI科学家和FAIR实验室的创始人
                    推动FAIR发布了众多具有影响力的开源项目（如PyTorch），
            Yoshua Bengio：中文名是 约书亚·本吉奥
                序列概率模型
                    在1990年代和2000年代初，他的团队在将神经网络应用于序列数据（如文本、语音）方面做出了开创性工作。
                    他们提出的神经语言模型（2003年）是这一领域的里程碑。
                    这项工作首次展示了神经网络可以用于建模序列中下一个词的概率，
                    为后来的词嵌入（Word Embedding）和整个现代神经自然语言处理（NLP）领域铺平了道路。
                    今天所有基于Transformer的模型（如GPT、BERT）都可以追溯到这个思想源头。
                深度学习代表作的合著者
                    他与伊恩·古德费洛和亚伦·库维尔合著的《深度学习》（俗称“花书”）是该领域最权威的教科书，系统地梳理和构建了深度学习的知识体系，培养了全球无数学生和研究者。
                生成式模型的开创性研究
                    他的团队在生成对抗网络（GAN）的理論发展和变分自编码器（VAE）等生成式模型上做出了基础性贡献。这些技术如今被广泛用于图像生成、数据增强等领域。
            他们三人因在深度学习领域的奠基性工作而共享了2018年的图灵奖，被誉为 AI 三巨头。
        华人
            李开复
            李宏毅
            李飞飞
            吴恩达
            陆奇
            黄仁勋
            苏姿丰
            梁见后 超微电脑（Super Micro Computer） 主要是做服务器的
            梁文峰
            Alexandr Wang
        其它
            Georgi Gerganov
    相关的框架
        python的库
            Torch
            TensorFlow
                TensorFlow Lite 只能运行模型，不能用于训练模型，一般用于移动设备或边缘设备
                    TensorFlow Lite(TFLite) 现在改名成 LiteRT（Lite Runtime ）
                TensorFlow.js 是 TensorFlow 的 js 版，原本有的功能 js版基本都有
                TFX(TensorFlow Extended)
            Keras
                Keras 是用于构建和训练深度学习模型的 TensorFlow 高阶 API
            sklearn 这个主要用于学习
        ML.NET
        Apache SINGA
        Apache Spark MLlib
    相关的书籍和仓库
        Deep Learning 中文翻译 https://github.com/exacity/deeplearningbook-chinese
        深度学习500问 https://github.com/scutan90/DeepLearning-500-questions
        数学要素 https://github.com/Visualize-ML/Book3_Elements-of-Mathematics
            这是一套系列丛书，一共有七本 https://github.com/Visualize-ML/Book3_Elements-of-Mathematics/blob/main/鸢尾花书_整体布局.pdf
        如何入门人工智能科研 https://github.com/WengLean/hands-on-research-tutorial
        动手学深度学习（Dive into Deep Learning，D2L.ai） https://github.com/d2l-ai/d2l-zh
        https://github.com/datawhalechina
            Datawhale是一个专注于AI与数据科学的开源组织 https://www.datawhale.cn/
                有课程 有认证
            从零开始的大语言模型原理与实践教程 https://github.com/datawhalechina/happy-llm
            从零开始构建智能体 https://github.com/datawhalechina/hello-agents
            人工智能的数学基础 https://github.com/datawhalechina/math-for-ai
            数学建模导论 https://github.com/datawhalechina/intro-mathmodel
        21节课教你开始构建生成式AI应用所需的一切知识
            https://github.com/microsoft/generative-ai-for-beginners
            https://github.com/microsoft/generative-ai-for-beginners/blob/main/translations/zh/README.md
        ApacheCN
            https://github.com/apachecn/Interview
            https://github.com/apachecn/ailearning
            https://github.com/apachecn/ai-roadmap
        AI工具集 https://ai-bot.cn/
        多智能体框架 https://github.com/geekan/MetaGPT
        google 的机器学习教程 https://developers.google.com/machine-learning?hl=zh-cn
        tensorflow 的教程 https://www.tensorflow.org/resources/learn-ml?hl=zh-cn
        大规模语言模型：从理论到实践
            https://intro-llm.github.io
            https://github.com/intro-llm/intro-llm.github.io
            https://intro-llm.github.io/chapter/LLM-TAP-v2.pdf
    Kaggle
        这是一个类似 leetcode 的平台，题目内容是数据分析相关的
        官网 https://www.kaggle.com/
        《Python机器学习及实践：从零开始通往Kaggle竞赛之路（2022年度版）》
            https://book.douban.com/subject/36143721/
            https://github.com/godfanmiao/ML-Kaggle-Github-2022
        Kaggle 的官方入门书籍，但没有中文版
            https://github.com/PacktPublishing/The-Kaggle-Book
        ApacheCN 中对 kaggle 的介绍
            https://github.com/apachecn/Interview/tree/master/docs/Kaggle
            https://github.com/apachecn/Kaggle
    现在的人工智能缺乏可解释性，可能就像过去的微积分的无穷小一样，虽然无穷小的定义在第二次数学危机才算解决了，但是并不妨碍十七，十八，十九世纪的数学家和工程师使用微积分
    ollama
        安装
            直接从官网下载 https://ollama.com/ ，哪种系统都适用
        使用
            查看帮助 ollama --help
            拉取模型 ollama pull deepseek-r1:1.5b
            运行模型 ollama run deepseek-r1:1.5b
                模型运行后可以直接在命令行里和模型对话
            列出已存在的模型 ollama list
            启动rest服务 ollama serve
                启动rest服务后可以通过http接口和模型对话
                curl http://localhost:6399/api/generate -d '{
                    "model": "deepseek-r1:32b",
                    "prompt":"Why is the sky blue?"
                }'
            ollama 的命令和docker 很像
            可以通过修改环境变量来设置 ollama 的端口
                只修改端口 OLLAMA_PORT=8080
                修改地址和端口 OLLAMA_HOST=0.0.0.0:8080
            ollama 默认启用 OpenAI 兼容模式，也可以通过环境变量显式设置
                OLLAMA_OPENAI_COMPATIBLE=1
            ollama 的环境变量通常要在 systemd 里修改
                sudo systemctl edit ollama
        openai api
            原则上每个请求都需要在http头带上 key
                Authorization: Bearer sk-xxxxxxxx
            post 请求都要带上
                Content-Type: application/json
            遇到汉字或其它非ascii字符可能需要转换成 Unicode编码，\u9047
            {host}/v1/models
            {host}/v1/models/{model-name}
            {host}/v1/embeddings
                {
                    "model": "deepseek-r1",
                    "input": "Say somethings"
                }
            {host}/v1/completions
                {
                    "model": "deepseek-r1",
                    "prompt": "Say somethings"
                }
            {host}/v1/chat/completions
                {
                    "model": "deepseek-r1-0528",
                    "messages": [
                        {"role": "system", "content": "You are a useful assistant"},
                        {"role": "user", "content": "\u9047\u5230\u4F60\u6211\u611F\u5230\u5F88\u9AD8\u5174"}
                    ],
                    "stream": false
                }
            还有很多，但这几个最常用，兼容性也很好
            一些平台自称兼容openai api其实也就兼容这几个接口
        前端
            openwebui
            https://github.com/ollama-ui/ollama-ui
            windows 的ollama自带一个简易的ui
财政、经济、金融、股票、基金、量化
    交易（trade） 货币 贷款 存款 汇兑 股票（stocks） 债券（bonds） 外汇 期货（futures） 基金（funds）
    证券（Security）不是实物商品，而是一种法律承认的、可流通的权利凭证
    REITs（不动产信托）
    基础资产（Underlying Asset）
    ETF（Exchange Traded Fund）——交易型开放式指数基金
    QDII（Qualified Domestic Institutional Investor）——合格境内机构投资者
    FOF（Fund of Funds）——基金中的基金
    LOF（Listed Open-ended Fund）——上市型开放式基金
    CEF（Closed-End Fund）——封闭式基金
        中国基金法规定，开放式基金必须“可申购赎回”，封闭式基金仅限于有固定期限的封闭运作（如 3 年、5 年封闭期），到期后转开放或清算。
        中国市场上所谓的“封闭式基金”其实是定期开放式基金（如 3 年封闭期），到期后可赎回，不上市交易。
    金融衍生品/金融衍生工具
        Derivative（衍生品）
        港澳称金融衍生产品
        台湾称衍生性金融商品
        金融衍生品是以一种或多种基础资产为标的，其价值取决于这些基础资产价格或指标表现的金融合约
        什么是 标的 ？
        什么是 金融合约（Financial contracts） ？
        什么是 对冲交易 ？
        OTC
            Over The Counter （在柜台上）
            中文通常译为 “场外交易”
            源于早期股票或债券交易时，投资者直接在经纪商的柜台上进行买卖，而不是通过集中化的交易所（exchange）。
            与之相对的是 “场内交易”（Exchange-Traded），即在正规交易所进行的交易。
        四大类衍生品
            期货（futures） 期权（Options） 远期合约（Forwards） 交换（Swaps）
    现代意义的银行大概在14世纪出现
        存款 汇款 贷款 换汇（currency exchange） 保险箱 代销（保险，基金）
    股份制公司大概在16世纪出现
    角色
        政府
        个人
        交易所 -> 也可以算作公司
        公司
            一般的公司
            银行 券商 保险公司 基金公司 机构投资者（保险和基金也是机构）
        企业是通过券商发债的
    什么是 回测
    什么是 因子挖掘
        因子（Factor） 是指能够解释资产收益差异的可量化特征
        因子挖掘（Factor Mining） 是指通过系统化的数据科学和统计方法，
        从原始数据中识别、构建和验证能够预测资产收益差异的特征变量（即“因子”）的过程。
        这些因子是量化策略的核心基础，用于构建多因子模型以获取超额收益。
        经典因子示例：
            价值因子：市盈率（PE）、市净率（PB）、股息率。
            动量因子：过去12个月收益率、短期价格趋势。
            规模因子：公司市值大小。
            质量因子：ROE（净资产收益率）、资产负债率。
        因子挖掘的核心目标 
            发现新因子：从传统数据（如财务报表、行情数据）或另类数据（如卫星图像、社交媒体情绪、供应链数据、文本新闻）中提取未被广泛认知的预测信号。
            优化现有因子：改进传统因子的计算方式（如将“市盈率”与“盈利增长”结合，构建“动态价值因子”）。
            提升策略鲁棒性：通过多因子组合降低单一因子失效的风险。
    关键指数
        大A
            上证指数 sh.000001
            深证 sz.399106 	深证综指 	深证综合指数
            创业 sz.399102 	创业板综 	创业板综指
            科创50 sh.000688
            中证A50
            中证A500
            中证500 sh.000905
            中证800
            沪深300 sh.000300 	沪深300 	沪深300指数
            上证50
            深证100
            具体板块的指数？
        港股
            恒生
            国企
            恒生科技
        美股
            指标准普尔500指数（S&P 500）
            道琼斯工业平均指数（DJIA）
            纳斯达克综合指数（NASDAQ Composite）
            纳斯达克100
        其它
            黄金价格
            石油价格
            日经指数
            富时指数
    有哪些可以提供数据的网站
        新浪财经
        东方财富
        雅虎财经(Yahoo Finance)
        google财经 但数据似乎比 微软和雅虎 都要少
        同化顺
        雪球 https://xueqiu.com/stock/screener
        微软 https://www.msn.com/zh-cn/money/explorecenter
        腾讯财经 http://qt.gtimg.cn/q=sh600000 https://sqt.gtimg.cn//?q=sh000001
        akshare https://akshare.akfamily.xyz/introduction.html
        证券宝 http://www.baostock.com
        tushare https://tushare.pro/ 需要注册，但也是免费的
        openctp
            https://github.com/openctp/openctp 这个仓库里有不少接口
            http://www.openctp.cn/
            CTP （China Trading Platform 中国交易平台）
            CTP 是由上期技术（上海期货信息技术有限公司）开发的一套标准化金融交易接口
                CTP 最初由中国金融期货交易所（CFFEX）推出，主要用于期货、期权等衍生品的程序化交易。
                它提供了一套标准的 API 接口（即 CTP API），供开发者编写自动化交易程序，连接期货公司柜台系统进行行情获取、下单、撤单等操作。
                传统上，个人开发者或机构常使用“SimNow”平台提供的模拟环境来测试基于 CTP 接口的程序。
    股票交易和分析软件
        同花顺 大智慧 指南针 东方财富 信达通 钱龙 腾讯自选股
        通达信 - 被许多民间高手和游资使用，职业交易者较为青睐
            因为最大优势就是职业抄手的通达信界面全是根据自己的看盘习惯和风格重新定制的；其次基本上所有指标都可以兼容
    同花顺都有哪些产品和服务
        电脑软件
            免费
            远航
            财富先锋
            决策先锋
            金融大师
        saas平台
            问财
            顾投平台
            量化回测 supermind https://quant.10jqka.com.cn/view/ 这个好像有新闻数据的
            量化策略平台 backtest https://backtest.10jqka.com.cn/backtest/app.html
    有哪些量化交易的平台，即使只有回测或模拟盘也可以
        www.fmz.com
        PandaAI 量化因子库
            https://www.pandaai.online/
            https://github.com/PandaAI-Tech/panda_factor
        阿布量化（ABU）
            http://www.abuquant.com/
            https://github.com/bbfamily/abu
        QUANTAXIS
            https://github.com/yutiansut/QUANTAXIS
        bigquant 的知识库 https://bigquant.com/wiki/home
    github 相关的仓库
        TradingAgents：基于多智能体大语言模型的金融交易框架 https://github.com/TauricResearch/TradingAgents
        基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版  https://github.com/hsliuping/TradingAgents-CN
        强化学习交易股票 https://github.com/sunnyswag/StockRL
        Qlib是一个面向人工智能的量化投资平台,旨在实现潜力,利用人工智能技术在定量投资中创造价值,从探索想法到实施生产。
            https://github.com/microsoft/qlib
        中文金融大语言模型 https://github.com/FudanDISC/DISC-FinLLM
        开源股票市场追踪与分析平台 https://github.com/Open-Dev-Society/OpenStock
        面向金融K线图的开源基础模型 https://github.com/shiyu-coder/Kronos
            可以配合 qlib 使用
        https://github.com/emcie-co/parlant
        https://github.com/stanfordnlp/dspy
        Fin-Agent https://github.com/YUHAI0/fin-agent
            Fin-Agent 是一个基于 DeepSeek 等大模型和 Tushare 金融数据的智能金融分析代理
电子支付，区块链，数字货币
    名词
        数字货币 digital currency
        虚拟货币 virtual currency
        加密货币 crypto currency
        电子货币 electronic currency
        电子支付 electronic payment
        电子现金 electronic cash
        区块链 block chain
    电子支付
    区块链的相关介绍
        共识算法
        有哪些基于区块链的应用
        两个核心
            分布式系统
            密码学
    数字货币
    比特币的相关介绍(Bitcoin)
        bit 比特
        coin 硬币
        比特币的交易原理？
            什么是手续费？
    除了比特币之外的主要的数字货币
        以太坊 (Ethereum, ETH): 以太坊是一个支持智能合约的区块链平台，允许开发者构建去中心化应用（DApps）。
        泰达币 (Tether, USDT): 作为一种稳定币，USDT 的价值与美元挂钩，通常用于在加密货币市场中作为交易媒介。
        瑞波币 (XRP): 瑞波币旨在为银行和金融机构提供快速、低成本的跨境支付解决方案。
        币安币 (BNB): 由币安交易所发行，最初用于支付交易手续费，现在也用于其生态系统中的多种应用。
        卡尔达诺 (Cardano, ADA): 一个以科学研究为基础的区块链平台，旨在提供更安全和可扩展的智能合约功能。
    比特币的衍生币
    以太坊(Ethereum)
    什么是智能合约(Smart Contract)
    交易所
        币安（Binance）
        Bitfinex
            Bitfinex 和 USDT 都是由其母公司 iFinex Inc 管理运营的，所以普遍认为 Bitfinex 和 USDT 是兄弟公司
        Coinbase - 全球第二大加密货币交易所，特别在美国市场占据主导地位
        Huobi (火币)
        HashKey Exchange - 香港持牌加密货币交易所
    什么是NFT(非同质化代币 Non-Fungible Token)
    什么是元宇宙(Metaverse)
        元宇宙一词起源于1992年的科幻小说《雪崩》，是“元(meta)”和“宇宙(universe)”的合成词。
    什么是密码朋克(Crypto punk)
    什么是稳定币（Stablecoin）
        泰达币（英语：Tether，货币代号USD₮或USDT）
    什么是web3
    什么是 混币器
        Cryptocurrency tumbler
        Coin Mixer
        混币器的原理是什么
        中心化混币器
            用户信任第三方服务商来处理和混合资金，存在资金被盗风险
        去中心化混币器
            利用智能合约，由代码自动完成混合过程，理论上更安全
        隐私币
FIRE和财富自由和躺平
    生活水平的分级
        赤贫 贫穷 温饱 小康 中产 富裕 极富
    财富自由
        不需要工作的前提下可以一直保持 富裕或以上 的生活水平
    躺平
        定义1：财富自由
        定义2：成年人不再积极工作/学生不再积极提高成绩
        躺平是指不再积极工作
        贫穷有贫穷的躺平方式
        富裕有富裕的躺平方式
        https://github.com/phodal/tangping
        最低生活保障
        最低工资
        被动收入
    FIRE
        定义
            Financial independence,Retire early（财务独立，提早退休）
            通过降低物欲，过极简的生活，迅速攒够生活费的25倍，靠4%的利息生活，
            达到逃离“不开心”的工作，去追求自己喜欢的生活方式。
            4% 是收益率减通胀率，不是理财的收益4%
            FIRE 并没有明确提及生活水平，笔者认为至少都要有 小康 的水平吧
        分类
            FatFIRE 肥FIRE
                进入 FIRE 后依然保持中产或以上的生活水平
            RegularFIRE 传统FIRE
                有计划地储蓄，储蓄达到一定金额后通过投资理财的被动收入支付生活成本
                一般目标金额通常是 一年生活费的25倍 ， 一般假设投资理财一年会有 4%收益
            LeanFIRE 瘦FIRE
                尽力储蓄，以求尽快进入FIRE状态，强调很高的储蓄率和很低的生活费
            BaristaFIRE 咖啡师FIRE
                储蓄达到一定金额后，辞去传统的工作，从事某种形式的兼职，通过储蓄的投资理财和兼职收入达到FIRE的状态
            CoastFIRE 滑行FIRE
                储蓄达到一定金额后，不再积极储蓄，然后由投资理财让这笔储蓄通过投资理财在计划退休年龄达到可以FIRE的金额

excel 相关经验
    冻结单元格
    筛选
    统计公式
        求和 平均值 中位数 众数 方差 标准差 极差
    数据透视
    条件格式
    格式验证
    生成图表
    lookup/vlookup/hlookup/xlookup
        xlookup 是 excel2021 之后才有的函数
    INDEX/MATCH
    宏
    vba
    兼容性由大到小
        函数 > 宏 > vba
    格式
        xls  xcel 2003 及更低版本的默认格式
        xlsx Excel 2007 及更高版本的默认格式
        xlsm 带有宏的excel
        xltx excel模板
        xltm 带有宏的excel模板
        ods 开放文档电子表格
        ots ods的模板
        wps 的格式应该也可以打开


数据透视
    枢轴表（英语：pivot table）也翻译成透视表，是用来汇总其它表的数据。
    首先把源表分组（grouping），
    然后对各组内数据做汇总操作如排序、平均、累加、计数或字符串连接等。
    透视表用于数据处理，在数据可视化程序如电子表格或商业智能软件中常见。
    例子
        最简单的例子：
            第一张表包含一列数，透视表仅含一行一列为源表该列的均值。
        稍微复杂点的例子，
            源表有两列分别为性别与“身高”，每行给出一个人的性别与高度；
            透视表有两行两列，在“性别”列分别写“男性”与“女性”，在“身高”列分别写对应性别的平均身高。
        更为复杂与更为典型的例子，
            源表有列“月份”、“销售员”、“产品”、“销售额”，每行给出一个销售员在某个月度卖出的某种产品的金额；
            透视表第一列是“销售员”用于写其名字，其余列还有“产品名”与“总销售”用于汇总该产品在该销售人卖出的销售总额。

整理各个 api 的资料
    供应商 网址 url key 模型名 上下文大小（总体大小 单次输入大小 单次输出大小） token限制/请求次数限制
    github
        网址
            https://docs.github.com/en/github-models/quickstart
            https://github.com/marketplace?type=models
            https://docs.github.com/en/github-models/use-github-models/prototyping-with-ai-models#rate-limits
        url
            https://models.github.ai/inference/chat/completions
        模型名
            low 每天 150 次调用 8000 in, 4000 out
                openai/gpt-4.1-mini
                    1049k input · 33k output
                microsoft/Phi-4
                    16k input · 16k output
                mistral-ai/Codestral-2501
                    256k input · 4k output
            hight 每天 50 次调用 8000 in, 4000 out
                openai/gpt-4.1
                    1049k input · 33k output
                deepseek/DeepSeek-V3-0324
                    128k input · 4k output
                meta/Llama-3.3-70B-Instruct
                    128k input · 4k output
                meta/Meta-Llama-3.1-405B-Instruct
                    131k input · 4k output   
            DeepSeek-R1-0528 每天 8 次调用
                128k input · 4k output
                4000 in, 8000 out
            xAI Grok-3 每天 15 次调用
                131k input · 4k output
                4000 in, 8000 out
            xAI Grok-3-Mini 每天 30 次调用
                131k input · 4k output
                4000 in, 8000 out
    阿里百炼
        网址
            https://bailian.console.aliyun.com
            https://help.aliyun.com/zh/model-studio/models
            https://help.aliyun.com/zh/model-studio/model-pricing
            用支付宝扫码登录
        url
            https://dashscope.aliyuncs.com/compatible-mode/v1
        模型名
            仅供免费体验 免费额度用完后不可调用
                deepseek-r1-distill-llama-70b
                    输入输出各100万Token，上下文 32，输入 32，输出 16
            限时免费
                deepseek-r1-distill-llama-8b
                    上下文 32，输入 32，输出 16
                deepseek-r1-distill-qwen-1.5b
                    上下文 32，输入 32，输出 16
                qwen2.5-1.5b-instruct
                    上下文 32，输入 30，输出 8
                qwen2.5-coder-1.5b-instruct
                    上下文 32，输入 30，输出 8
                qwen2.5-coder-0.5b-instruct
                    上下文 32，输入 30，输出 8
    cloudflare
        网址
            https://developers.cloudflare.com/workers-ai/platform/pricing/
            https://developers.cloudflare.com/workers-ai/models/
        url
            https://api.cloudflare.com/client/v4/accounts/{account_id}/ai/v1/chat/completions
        模型名
            @cf/deepseek-ai/deepseek-r1-distill-qwen-32b
            @cf/meta/llama-3.1-8b-instruct
            @cf/qwen/qwen2.5-coder-32b-instruct
        每天有一定的免费额度，但计算方式有点复杂，可以简单但不严谨地理解为每天只有20次左右
    mistral
        devstral-2512
            https://docs.mistral.ai/models/devstral-2-25-12
            上下文 256
            暂时还是免费的 https://mistral.ai/pricing#api-pricing
    openrouter 也有不少免费的模型
    腾讯云 这个是收费的
主要任务 次要任务 不重要的任务
    主要任务 最好的 模型 例如 满血原生deepseek-r1
    次要任务 一般的 模型 例如 qwen-turbo qwen-flash
    不重要的任务 免费的api 或 本地的模型


模型常见的后缀
    Base：基础通用模型，适合进一步微调
    Chat：优化对话交互，擅长多轮对话
    Instruct：专注指令执行，精确完成任务
        一次生成长文本
    Thinking：强化推理能力，展示思考过程
        被设计用来将复杂问题分解成更小、可管理的步骤并逐步解决
        这些模型专门设计具有结构化的思考过程，然后给出输出结果
        在提供最终答案之前，通过逐步解决问题的方式来处理信息的过程
        在 openai 这类模型被称为 thinking model （思考模型）
        在 deepseek 这类模型被称为 reasoning model （推理模型）， deepseek-r1 的 r 就是 reasoning 的意思
基座模型（base） 聊天模型（chat） 指令模型（instruct）
Turbo/Flash 速度或效率优化，可能通过模型压缩、架构调整实现快速响应
code
math
vision

Claude
    Haiku
    Sonnet
    Opus
分别代表低、中、高三个不同级别的模型


https://github.com/fmaclen/hollama
A minimal LLM chat app that runs entirely in your browser 



https://github.com/docling-project/docling
多格式文档解析和导出工具。这是一个由 IBM 开源的 Python 工具，
专门用于将各类文档转化为适合生成式 AI 使用的格式。
它能够将 PDF、DOCX、PPTX、图片、HTML、Markdown 等多种流行文档格式，
导出为 Markdown 和 JSON 格式

一个通用的文档转换工具，似乎自持很多格式
https://pandoc.org/index.html
https://github.com/jgm/pandoc

图灵测试
图灵测试是图灵在他的论文《计算机器与智能》中提出的，
这篇论文于1950年10月发表于哲学期刊《心灵》中
文中预言了创造出具有真正智能的机器的可能性。
由于注意到“智能”这一概念难以确切定义，他提出了著名的图灵测试


达特茅斯夏季人工智能研究计划
（英语：Dartmouth Summer Research Project on Artificial Intelligence）
由约翰·麦卡锡等人于1955年8月31日发起，
旨在召集志同道合的人共同讨论“人工智能”（此定义正是在那时提出的）。
会议持续了一个月，基本上以大范围的集思广益为主。
这催生了后来人所共知的人工智能革命。 
香农也是这个会议的发起人之一
会议设定了七个议题，分别为
    自动计算机
    如何对计算机进行编程以使用语言
    神经网络
    计算规模理论
    自我改进
    抽象
    随机性与创造性

2006 年，论文《A Fast Learning Algorithm for Deep Belief Nets》在《Neural computation》发布
2009 年，李飞飞在斯坦福大学完成 ImageNet 的初始版本，包含 1500 万张图像，涉及 22000 个类别。
2012 年，杰弗里·辛顿的团队发明的 AlexNet 神经网络算法在第三届 ImageNet 挑战赛上获胜，深度学习革命时代到来。
2015 年，OpenAI 成立。
2016 年，DeepMind 开发的 AlphaGo 4:1 击败韩国围棋冠军李世石。
2017 年，DeepMind 团队发表《Attention Is All You Need》论文，提出 Transformer 的新型神经网络模型。
2018 年，GPT-1 发布
2019 年，GPT-2 发布
2020 年，GPT-3 发布
2022 年 12 月，ChatGPT 发布 GTP-3.5
2023 年 3 月，GPT-4 发布
2023 年 12 月，deepseek v3
2024 年 1 月，deepseek r1
2024 年 5 月，GPT-4o 发布


Hinton和他的学生Simon Osindero、Yee-Whye Teh
在2006年发表在《Neural computation》上的论文，
主要提出了利用RBM（受限玻尔兹曼机）、contrastive divergence（对比散度）算法、up-down算法等方法对网络进行逐层训练和微调，
解决多层网络训练困难的问题。

在2006年之前，神经网络（尤其是多层神经网络，即后来的深度学习）已经沉寂了相当长的时间。尽管概念早已存在，但它们面临几个致命问题：
    梯度消失/爆炸问题：
        在训练多层网络时，误差从输出层反向传播到输入层时，梯度（用于调整权重的信号）会变得指数级地小（或大）。
        这意味着靠近输入层的网络参数几乎得不到有效的更新，导致深层网络无法被有效训练。本质上，人们不知道如何训练一个“深”的网络。
    局部最优陷阱：传统的训练方法很容易让模型陷入局部最优解，而无法找到全局最优解。
    算力和数据不足：虽然当时算力在增长，但尚不足以支撑大规模深度网络的训练。同时，互联网上的大数据集（如ImageNet）也还未普及。
因此，在2006年之前，神经网络被认为是一种没有前途、难以实用的技术。
2006年的关键突破：杰弗里·辛顿的“深度学习”论文
2006年，杰弗里·辛顿和他的学生鲁斯兰·萨拉赫丁诺夫在《科学》杂志上发表了一篇里程碑式的论文《A Fast Learning Algorithm for Deep Belief Nets》。
这篇论文的核心贡献在于提出了一种高效训练深度神经网络的新方法：
    逐层预训练：他们提出，可以先用一种叫做“受限玻尔兹曼机”的无监督学习算法，一层一层地对网络进行“预训练”。这个过程不是为了直接完成任务，而是为了给网络的权重找到一个良好的初始值。这个初始值位于一个更容易找到全局最优解的区域。
    微调：在完成逐层预训练后，再使用传统的反向传播算法（有监督学习）对整个网络进行“微调”。
这个“逐层预训练 + 微调”的策略，巧妙地绕开了“梯度消失”问题，首次让人们能够成功地训练一个真正“深”的神经网络。 辛顿将这种方法称为“深度学习”，以此与传统的“浅层”机器学习方法（如支持向量机）区分开来。



完全图灵测试普通的图灵测试一般避免审问者与被测试计算机发生物理上的互动，
因为物理上模拟人（比如像模拟人的外表）并不是人工智能的研究范畴。
然而一些人工智能可能涉及一些人机在物理上的交互，所以人们又拓展出了“完全图灵测试”。
在完全图灵测试中，可以包含必要的人机在物理层面上的交互。
但是为了通过完全图灵测试，还需要在普通图灵测试之外另外两项额外技术课题。
询问者还可以测试受试者的感知能力（需要电脑视觉），和受试者操纵物体的能力（需要机器人学）。




https://app.aibase.com/
一个很好的ai工具网站，有 ai榜单 和 ai能力对比 和 ai部署服务器配置模拟器


“氛围编程”（Vibe Coding）是一种全新的编程理念，核心思想是通过AI辅助实现沉浸式开发，关注结果而非过程。
开发者只需用自然语言描述需求，AI会自动生成代码并调整，直到结果符合预期。
这种方式极大地降低了编程门槛，让非技术人员也能快速实现创意。


llm 时代普通程序员能做的事
    前端的ui
    提示词工程/上下文工程
    rag
    mcp
    Workflow 工作流
    本地部署llm
    使用 氛围编程（Vibe Coding） 加速开发
    调用api实现各种应用/开发 agents或chatbot


尝试使用云服务实现一次微调？


提示词工程的 多轮对话 ？


OpenAI 的 DALL-E 和 Stable Diffusion

大模型
    开发商
        通常开发商都有自己的api和开发平台
    供应商 这里特指只提供接口的
        OpenRouter
            好像除了 OpenRouter 之外没有特别好的专门的 供应商
        https://dmxapi.cn/
            一个 Key 用全球大模型
            仅修改 Key和 Base url就可使用 
    开发平台
        训练 和 微调



LLaMA的全称是
Large Language Model Meta AI，
直译为“大语言模型元AI”。
由于“Llama”在西班牙语中意为“羊驼”，因此社区也将其昵称为羊驼系模型。

LLa M A
LLa -> Large Language Model
M -> Meta
A -> AI



Hugging Face 最流行的模型库
ModelScope 由中国厂商主导的模型库
ollama 用于本地部署 ai ，也提供模型库
lm studio 用于本地部署 ai ，也提供模型库
vLLM 用于本地部署 ai ，没有提供模型库，一般是生产环境，入门比较难



BLOOM
BigScience Large Open-science Open-access Multilingual Language Model
https://bigscience.huggingface.co/
https://bigscience.notion.site/BigScience-214dc9a8c1434d7bbcddb391c383922a
https://huggingface.co/bigscience

BLOOM 是一个由 BigScience 工作组主导、社区驱动开发的大型开源多语言预训练语言模型。
目标是提供一个可公开审查、可重复、支持多语言研究与应用的替代闭源大模型。

BigScience 是一个由 Hugging Face 发起、面向全球的开放协作研究工作坊，
旨在以大规模、多学科、开源和以伦理为导向的方式开发大型多语种语言模型与配套数据集。
该项目集合了来自学术界、工业界和独立研究者的数百到上千名贡献者，参考 CERN 等大型科学合作模式，
把大型语言模型（LLM）建设当作“公共科研基础设施”来组织。


RLHF
Reinforcement Learning from Human Feedback
人类反馈强化学习


Zero-shot / Few-shot Learning（零样本/少样本学习）


