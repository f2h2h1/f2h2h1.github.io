为什么无法学习新知识了？
    不知道从哪里开始学习
        没有明确的学习路径
    理论知识记不住
    缺少实践机会
    学会了，如何证明自己学会了？
如何判断自己是否学会了某一项技能？
    特别是数学相关的？
        感觉看原理时一看就懂，实践时一做就错
数学
    初等数学
        初等代数
        微积分之后的数学都可以叫做高等数学了
    微积分
    线性代数
    概率论
    数理统计
    离散数学
        数理逻辑
        集合论
        组合数学
        图论
        运筹学
        博弈论
        信息论
    最优化
从零开始学习数学建模
    我总想找到一种方法来应对所有类型的算法面试题
    或者说我总想找到一种方法来应对所有考试时遇到的数学题
    或者说我总想找到一种方法来应对所有考试时遇到的问题
    我们为什么可以把题目归类为一类相似的问题？
    题型的数量是不是可以无限地增加？
    数学建模需要哪些前置的知识？
    第1步	识别问题
    第2步	做出假设
        a.识别变量并对变量进行分类
        b.识别变量和子模型之间的相互关系
    第3步	求解模型
    第4步	验证模型
        a.表述了问题吗？
        b.在通常意义下它有意义吗？
        c.用实际数据来验证该模型
    第5步	实施模型
    第6步	验证模型
    数学建模 https://book.douban.com/subject/1231271/
    数学建模方法与分析 https://book.douban.com/subject/1392709/
    感觉数学建模的那些算法和机器学习的十分相似，可能就是同一套。。。
    算法
        预测
        分类
        最优化
    经典的机器学习算法
        线性回归算法 (Linear Regression)
        支持向量机算法 (Support Vector Machine, SVM)
        最近邻居/k-近邻算法 (K-Nearest Neighbors, KNN)
        逻辑回归算法 (Logistic Regression)
        决策树算法 (Decision Tree)
        k-平均算法 (K-Means)
        随机森林算法 (Random Forest)
        朴素贝叶斯算法 (Naive Bayes)
        降维算法 (Dimensional Reduction)
        梯度增强算法 (Gradient Boosting)
        遗传算法（Genetic Algorithm, GA）
        模拟退火（Simulated annealing, SA）
        蒙特卡罗方法（Monte Carlo method）
        马尔可夫链（Markov chain）
        隐马尔可夫模型（Hidden Markov Model, HMM）
    各种 人工智能/机器学习/深度学习/数据分析/数据挖掘 的模型
    这些模型各自的应用场景和优缺点
        这些模型有哪些经典的应用
    这些模型所对应的算法和算法对应的数学原理
        这些数学理论如何和机器学习的模型联系起来
        这些机器学习的模型如何和数学理论联系起来
        就是要双向连接
    这些模型在不同条件下的分类
        例如 有没有监督 训练样本有没有标签 是不是线性模型 用于分类还是用于预测 是不是概率模型 是不是生成式模型 是单模型还是集成模型
    这些 模型/算法 的发展历史
        例如 由谁提出的，在哪篇论文最先提到，有哪些变体
leetcode做题的一般套路
    要把问题抽象成数学问题
        要抽象成类似这样的函数
            答案=解答(输入)
        从写代码的角度大概就是三步
            读取和解释输入
            处理输入
            格式化输出
        多数 leetcode 的题目都会自动处理好第一步和第三步
        实际面试时可能依然要自己处理输入和输出
            代码随想录里把
                不需要处理输入输出的称为 核心模式
                需要处理输入输出的称为 ACM模式
                https://github.com/youngyangyang04/leetcode-master/blob/master/problems/%E5%89%8D%E5%BA%8F/ACM%E6%A8%A1%E5%BC%8F.md
    要准确地理解问题，然后选择正确的数据结构和算法
        理解 哪些是 已知 哪些是 未知 ，题目的目标是什么？要求哪个未知变量？
        列出 已知变量 和 未知变量
        列出 各个变量 之间的关系
    先学好理论再去做题
    如果一道题一直没思路就直接看答案
算法思想
    主要的算法思想 (algorithmic paradigm)
        穷举 (exhaustion) Brute 暴力
        递归 (recursion)
        贪心 (greedy)
        分治 (divide and conquer)
        剪支和搜索 (prune and search)
        回溯 (backtracking)
        动态规划 (Dynamic programming, DP)
            动态规划 约等于 深度优先搜索 + 回溯
        分支界限 (Branch and bound, BB B&B BnB)
            分支界限 约等于 广度优先搜索 + 回溯
    算法思想之所被称为思想是因为算法思想可以应用到不同的数据结构里
    一个具体的算法肯定是基于至少一个具体的数据结构
    一种数据结构通常至少会有三种算法
        遍历 搜索 排序
    简单但不严谨的比喻
        数据结构 是 食材
        算法 是 菜谱
        算法思想 是 烹饪方式
    为什么穷举也可以算作一种算法思想？
    迭代，递归，循环的区别
        循环 loop
            循环 强调 重复同一个操作
        迭代 iteration
            迭代 强调 下一次的输入会依赖上一次的输出
        递归 recursion
            递归 强调 函数自己调用自己
        递推是什么？
            递推没有对应的英文，通常用递归的英文 recursion
            递推可能是指递归也可能是指迭代
            简中网的文章大多会强调递推是自底向上，递归是自定向下
                从个人写代码的感受而言，递推和递归确实可以分成两种不同的情况
    算法思想 通常是来自数学上相关的学科 例如 运筹学 最优化 组合数学 这类
    有多种方法可以对算法进行分类
        根据应用分：
            按照算法的应用领域，可以分为
            基本算法，数据结构相关算法，几何算法，图论算法，规划算法，数值分析算法，加密解密算法，排序算法，查找算法，并行算法，数值算法……
        根据确定性分：
            确定性算法：有限时间内完成，得到结果唯一。
            非确定性算法：有限时间内完成，得到结果不唯一，存在多值性。
        根据算法的思路分：
            递归算法，穷举算法，贪婪算法，分治算法，动态规划算法等。
动态规划(Dynamic programming, DP)
    递归
    深度优先搜索
    贪心
    回溯和剪支
        回溯算法在尝试和回退中穷举所有可能的解，并通过剪枝避免不必要的搜索分支
    记忆化递归
    制表
        这个和滚动数组有什么联系？
    一些语境下，
        记忆（Memoization） 和 制表（Tabulation） 会被区分开来，
        把 记忆 称为 记忆化递归 或 备忘录；把 制表 称为 动态规划。
        或者把 记忆 和 制表 统称称为广义动态规划，把 制表 称为狭义动态规划。
    制表 可以看作是 优化后的 记忆
    通常情况下使用 记忆 需要更多的内存，
        在力扣刷题时，一些题目有内存限制，使用 记忆 可能会无法通过，
        但存在一些问题 制表 是无法解决的，依然需要使用 记忆 的方法
    例题
        斐波那契数列
            // 普通递归
            function fibonacci_1($n)
            {
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                return fibonacci_1($n - 1) + fibonacci_1($n - 2);
            }

            // 记忆化递归 备忘录
            function fibonacci_2($n)
            {
                static $ret = [];
                if (isset($ret[$n])) {
                    return $ret[$n];
                }
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                return fibonacci_2($n - 1) + fibonacci_2($n - 2);
            }

            // 动态规划
            function fibonacci_3($n)
            {
                $ret = new SplFixedArray($n + 1);
                $ret[0] = 0;
                $ret[1] = 1; // 边界条件
                for ($i = 2; $i <= $n; $i++) {
                    $ret[$i] = $ret[$i - 1] + $ret[$i - 2]; // 状态转移方程
                }
                return $ret[$n]; // 返回最优解
            }

            // 基于动态规划继续优化1 滚动数组
            function fibonacci_3($n)
            {
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                $ret = new SplFixedArray(3);
                $ret[0] = 0;
                $ret[1] = 1;
                $n = $n - 1;
                do {
                    $ret[2] = $ret[1] + $ret[0];
                    $ret[0] = $ret[1];
                    $ret[1] = $ret[2];
                    $n--;
                } while ($n > 0);
                return $ret[2];
            }
            // 基于动态规划继续优化2
            function fibonacci_3($n)
            {
                if ($n == 0) {
                    return 0;
                }
                if ($n == 1) {
                    return 1;
                }
                $a = 0;
                $b = 1;
                $n = $n - 1;
                do {
                    $ret = $b + $a;
                    $a = $b;
                    $b = $ret;
                    $n--;
                } while ($n > 0);
                return $ret;
            }
        背包问题 （Knapsack Problem）
            题干
                假设有一个背包，
                能够承载的最大重量为 W，
                同时有 n 个物品，每个物品 i 具有一个重量 wi​ 和一个价值 vi​。
                目标是选择一些物品放入背包中，使得所选物品的总重量不超过 W，并且总价值最大化。
            分类
                0-1背包
                    如果限定每种物品只能选择0个或1个，则问题称为0-1背包问题
                完全背包/无界背包问题
                    如果不限定每种物品的数量，则问题称为无界背包问题
                多重背包/有界背包问题
                    如果限定物品j最多只能选择bj个，则问题称为有界背包问题
    先有循环，后有表格，表格就是两层循环的数组展开后的结果
    参考
        https://oi-wiki.org/dp/
        https://github.com/labuladong/fucking-algorithm/blob/master/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E7%B3%BB%E5%88%97/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%AF%A6%E8%A7%A3%E8%BF%9B%E9%98%B6.md
        https://mp.weixin.qq.com/s/1V3aHVonWBEXlNUvK3S28w
数据分析/机器学习/数据挖掘/数据科学/大数据
    名词
        artificial intelligence AI
        big data 大数据
        statistic 统计
        statistical analysis 统计分析
        Data Analysis 数据分析
        Data Mining 数据挖掘
        Machine Learning 机器学习
        data scientist 数据科学
        data source 数据源
        Data mesh 数据网络
        OLTP
            online transaction processing
            在线 事务 处理
        OLAP
            online analytical processing
            在线 分析 处理
        HTAP
            Hybrid Transaction and Analytical Process
            混合 事务 和 分析 处理
        DB
            Data Base
            数据 库
        DL
            Data Lake
            数据 湖
        DW / DWH
            Data Warehouse
            数据 仓库
        DM
            Data Mart
            数据 集市
        KB
            Knowledge Base
            知识 库
        ETL
            Extract-Transform-Load
            抽取-转换-加载
        ELT
            Extract-load-transform
            抽取-加载-转换
        DSS
            Decision Support System
            决策 支持 系统
        BI
            Business Intelligence
            商业 智能
        data viz/vis
            Data visualization
            数据 可视化
        data lakehouse
            数据 湖仓一体
        data architecture
            数据 架构
    数据分析 使用 统计学 的方法 从已有的数据中 验证预设的假设或回答特定的业务问题
    机器学习 把已有的数据作为训练集(Training Set)，建立模型，用模型处理新的数据
    数据挖掘 使用 统计学 和 机器学习 的方法 从已有的数据中 发现 关联 或 趋势
    大数据
        大数据通常是指对大量的数据进行数据分析或数据挖掘
        只要数据量足够大就可以自称大数据
        大数据往往需要用到这些工具
            Hadoop系列
                hive hadoop MapReduce Lucene NDFS/HDFS Hbase Nutch
            google
                BigTable GFS
            流式处理框架
                ApacheSpark ApacheFlink ApacheSamza ApacheStorm
    数据平台
        数据管理
            数据采集
            数据存储
        数据分析（Data Analysis）
            数据统计/统计分析（狭义的数据分析）
            数据挖掘（机器学习）
        数据应用
            推荐
            广告
            数据可视化
    统计是总结过去，概率是预测未来，通过统计过去来预测未来？
    数据分析 可以由业务人员独立完成
    机器学习 和 数据挖掘 通常由it主导
    文档型数据库和关系型数据库本质上有些什么区别？文档型数据库出现的背景？
    列数据库和关系型数据库本质上有些什么区别？
    Symbolic AI 符号AI
    Explainable AI，XAI 可解释AI
    Neuro-symbolic AI 混合式神经-符号AI
    weak AI 弱AI
    strong AI 强AI
    artificial general intelligence，AGI 通用人工智能
    traditional AI 传统AI
        predictive AI 预测式AI
    generative AI 生成式AI
    可能用到的语言或工具
        Python R Julia Fortran SQL
        Spyder Jupyter RStudio
        Excel Octave MATLAB Mathematica SAS SPSS stata
        PowerQuery
            excel 2010 和 2013 pq 可以作为免费的加载项
            excel 2016 pq就内置在 excel 了
            pq 也可以用在免费的 Power BI Desktop 里
    相关的职业
        数据科学家（Data scientist）
            数据科学家分析复杂的数字数据，帮助企业做出决策。
            他们利用数据科学培训和先进的分析技术，包括机器学习和预测建模，发掘数据中隐藏的洞察分析。
        数据分析师（Data analyst）
            数据分析师将数据转化为信息，将信息转化为洞察力。
            他们使用统计方法从数据集中分析和提取有意义的趋势，通常是为了为业务策略和决策提供信息。
        数据工程师（Data engineer）
            数据工程师负责准备、处理和管理大数据基础设施和工具。
            还在组织内开发、维护、测试和评估数据解决方案，经常处理大量数据集来协助分析项目。
        机器学习工程师（Machine learning engineer）
            机器学习工程师专注于设计和实施机器学习应用。
            他们开发复杂的算法，可以从数据中学习并进行预测。
        商业智能分析师（Business intelligence analyst）
            商业智能 (BI) 分析师通过分析数据得出切实可行的洞察，帮助企业做出数据驱动的明智决策。
            他们通常使用 BI 工具将数据转换为易于理解的报告和可视化图表，以供业务利益相关者查看。
        数据可视化专家（Data visualization specialist）
            这些专家专注于数据的可视化表示。
            他们创建数据可视化，通过将数据置于可视化环境中来帮助最终用户了解数据的重要性。
        数据构架师（Data architect）
            数据构架师设计、创建、部署和管理组织的数据架构。
            他们定义不同数据实体和 IT 系统如何存储、使用、集成和管理数据。
    机器学习中算法/模型的分类方式
        任务类型
            分类 预测 最优化
        学习类型
            有监督 半监督 无监督 迁移学习 强化学习
        模型结构
            线性模型 非线性模型 集成模型
人工智能
    概述
        是什么
            用机器模拟人脑
        能做什么
            理想状态下，人能做什么，ai就能做什么
        有哪些流派
            符号主义（Symbolists）
            联结主义（Connectionists）
            行为主义（Behaviorism）
    发展历史
        经典的机器学习 -> 神经网络 -> 深度学习 -> 大语言模型
    数学基础
        初等数学
        四门基础
            微积分 线性代数 概率论 数理统计
        离散数学
            数理逻辑 集合论 组合数学 图论 运筹学 博弈论 信息论
        最优化
        数学建模
    计算机基础
        理论计算机科学
        408全家桶
            数据结构 计算机组成原理 操作系统 计算机网络
        数据库
        前端三件套
        软件工程
        常用的工具
    经典的机器学习
        五大流派
            符号主义（Symbolists）
            联结主义（Connectionists）
            贝叶斯派（Bayesians）
            进化主义（Evolutionists）
            类推主义（Analogizers）
            符号主义和联结主义和人工智能中的分类是一样的
            人工智能中的行为主义似乎没有什么存在感
            贝叶斯 进化主义 类推主义 在人工智能的流派中好像没有对应的分类
        GOFAI
            1985年，约翰·豪格兰在他的书《 人工智能：非常的想法 》中探讨了人工智能研究的哲学含义，
            将符号人工智能命名为GOFAI（Good Old-Fashioned Artificial Intelligence，指的是“有效的老式人工智能）。
            在机器人学领域 ，类似的术语是GOFR （“有效的老式机器人学”）。
            https://en.wikipedia.org/wiki/GOFAI
            GOFAI 通产包含 决策树 和 搜索算法（启发式搜索，对抗搜索）
        支持向量机 (Support Vector Machine, SVM)
        对于模型的分类，不同的标准会有不同的分类，就像对算法的分类一样
        两条路线
            自顶向下 从应用到原理
            自底向上 从原理到应用
        如何选择机器学习的算法
            https://learn.microsoft.com/zh-cn/azure/machine-learning/how-to-select-algorithms?view=azureml-api-1
            https://zhuanlan.zhihu.com/p/345855210
            https://scikit-learn.org/stable/machine_learning_map.html
        深度学习与机器学习 https://learn.microsoft.com/zh-cn/azure/machine-learning/concept-deep-learning-vs-machine-learning?view=azureml-api-2&viewFallbackFrom=azureml-api-1&WT.mc_id=docs-article-lazzeri
    神经网络（neural network）
    深度学习（Deep Learning）
    大语言模型（Large Language Model, LLM）
        自然语义处理 (Natural Language Processing, NLP)
        提示工程（Prompt Engineering）
            提示词模板
                背景介绍
                角色设定
                    明确角色
                    角色赋能
                具体任务
                    任务指令
                        任务步骤
                    约束条件
                输出格式
            分隔符
            ###
            ===
            选择哪种特殊字符并不重要，关键是这些字符足够独特，使得模型能将其识别为分隔符，而非常规标点符号
            微软的教程 提示工程技术 https://learn.microsoft.com/zh-cn/azure/ai-foundry/openai/concepts/prompt-engineering
        上下文工程（Context Engineering）
        提示链 (prompt chaining)
            提示链通过多轮对话，引导 LLM “思考” 方向，让 LLM 从简单任务开始，沿着设计好的“思考”方向逐步完成一个复杂推理
        思维链 (Chain of thought, CoT)
        AI Agent/bot/Generative AI/上下文窗口/微调/RAG/MOE
            微调（Fine-Tuning，FT）是再训练一次并加入新数据
            rag是在上下文或提示词里加入新数据
                rag 就是 知识库
                Retrieval-Augmented Generation
                检索增强生成
            AI Agent 就是 bot
                提示工程 是 Agent
                rag 是 Agent
            插件 (plugins) 就是 调用外部api
                在 工作流 里会用到 插件
            工作流 (workflow) 就是 字面意思
                和 cicd 里的工作流是一样的，只是过程中有大模型的参与
                参考一下腾讯的 混元 元宝 元器
            Function Call
            MCP（Model Context Protocol）
                MCP 是由 Anthropic 公司（Claude 模型） 推出的一个协议，
                它通过提供一种标准化的接口，LLM 应用可以访问外部信息、工具和资源。
                它相当于大模型的”HTTP协议”。
                    HTTP协议：使浏览器与服务器 交互标准化
                    MCP：使大模型与外部服务 交互标准化
            A2A（Agent2Agent）
            AG-UI（Agent-User Interaction Protocol，智能体用户交互协议）
                MCP协议——解决AI Agent和外部工具交互问题
                A2A协议——解决Agent间通信问题
                AG-UI协议——解决AI Agent与前端应用之间的交互标准化问题
            多Agent系统（Multi-Agent System, MAS）
            MOE
                Mixed Expert Models
                混合专家模型
            上下文（context）
                上下文窗口（context window）
                    这是模型在生成每个新token时实际参考的前面内容的范围
                上下文长度（context length）
                    它限制了模型一次性交互中能够处理的最大token数量
                    这是指模型单次可以处理的最大输入序列长度，通常以token数表示。
                    换句话说，这是模型可以同时“看到”的内容的最大数量。
                Context Length是一个静态的上限，涵盖了整个输入和输出过程中的所有token；
                Context Window则是一个动态的范围，每次生成token时模型实际参考的上下文。
                例子
                    假设一个模型的Context Length是2048，
                    你输入了一段包含1500个token的文本（prompt），
                    那么模型生成的响应最多只能有548个token（1500输入 + 548输出 = 2048总长度）。
                    如果这个模型的 Context Window是512 token，
                    那么在生成第513个token时，模型只能参考前面的512个token，而不是全部2048个token。
            向量库(Vector Database)
            参数（Parameters）
                权重参数（Weights）
                偏置参数（Biases）
                嵌入参数（Embeddings） EMB
            预训练（Pre-training）
            注意力机制（Attention Mechanism）
                自注意力机制（Self Attention Mechanism）
            ReAct (Reasoning and Acting) 推理和执行
            LangChain 和 LangGraph 和 langsmith
            n8n 和 Dify 和 coze 和 ComfyUI 和 Flowise 和 AutoGen 这类型的工具似乎还有很多
        满血版>满血版量化>蒸馏版>量化版(蒸馏量化版)
            满血就是没经过改动的
            量化就是可以运行在内存里的
            蒸馏(distill)就是阉割版
            量化版，一般语境下的量化版就是蒸馏量化版，就是可以运行在内存里的蒸馏版
            ollama 下载的都是量化版
            满血或蒸馏版
                显存 大于 模型的尺寸
            量化版
                显存+内存 大于 模型的尺寸
            满血 (full-powered/full-blooded/Full Version)
            模型压缩 (Model Compression)
                模型量化 (Model Quantization)
                模型蒸馏 (Model Distillation)
                模型裁剪 (Model Pruning)
                模型稀疏化 (Model Sparsity)
        模型权重
            浮点数据类型在IEEE 754-2019(2008)标准中进行了详细的定义，
            定义了不同精度的浮点数格式，如 binary16、binary32、binary64
            FP8 E4M3
                1标志位 4基数 3尾数
            FP8 E5M2
                1标志位 5基数 2尾数
                这两个也是由英伟达提出的
            binary16
                FP16
                floating point 16
                半精度浮点
                1标志位 5基数 10尾数
            brain floating point
                BFP16 BF16 bfloat16
                由Google Brain开发的，所以这个brain应该是Google Brain的第二个单词
                1标志位 8基数 7尾数
            TF32
                TensorFlow-32
                英伟达提出的代替FP32的单精度浮点格式
                19位大小
                1标志位 8基数 10尾数
            binary32
                FP32
                floating point 32
                单精度浮点
                1标志位 8基数 23尾数
            binary64
                FP64
                floating point 64
                双精度浮点
                1标志位 11基数 52尾数
            模型的训练一般用 fp32 tf32 bf16 fp16
            如果模型是 fp32 那么显存就需要模型大小的4倍，例如 70b 就需要 70*4= 280g 显存
            如果模型是 tf32 那么显存就需要模型大小的4倍，例如 70b 就需要 70*4= 280g 显存
                tf32 是引入的一种计算格式，主要用于加速FP32运算，但数据存储仍以FP32格式进行。
            如果模型是 bf16 那么显存就需要模型大小的2倍，例如 70b 就需要 70*2= 140g 显存
            如果模型是 fp16 那么显存就需要模型大小的2倍，例如 70b 就需要 70*2= 140g 显存
            如果模型是 fp8 那么显存就需要模型大小的1倍，例如 70b 就需要 70*1= 70g 显存
            如果模型是 int8 那么显存就需要模型大小的1倍，例如 70b 就需要 70*1= 70g 显存
            如果模型是 int4 那么显存就需要模型大小的0.5倍，例如 70b 就需要 70*0.5= 35g 显存
            通常会多预留一些显存，例如 28g 就用 30g显存，14g 就用 16g显存
            还有更复杂的混合精度
                fp8 和 int8 有什么区别？
                FP8 E4M3 和 FP8 E5M2 有什么区别？
                bf16 和 fb16 有什么区别？
                以我当前的水平，正确地理解这些区别似乎有一点困难
                只能简单但不严谨地理解为 没有区别
            32b的排名也很高，是因为参与排名的是原版
                平时在电脑部署的，是 4int 或 8int 的量化版
                要运行原版至少需要一张80g显存的显卡，消费级的显卡暂时还没有那么大的显存
                8int 32g
                4int 16g
            满血的deepseek R1一般是指FP8、671B权重的版本
                载入模型大概需要 671g显存，再加上一些余量，大概需要750g显存，
                国内实践一般用800g显存，大概就是10张80g的显卡
                FP8 仅能被英伟达新型GPU支持，国内会用fp16或BF16模拟，但会大大增加需要的显存
                用 fp8 的叫做原生满血
                用 fp16 的叫做转译满血
                    转译版理论上和原版一样的，但实践中往往会比不上原版，和原版的差距主要体验在转译团队的水平上
                用 int8 的叫做量化满血
                    美团有一个号称无损的int8量化版
                    https://tech.meituan.com/2025/03/07/meituan-int8-deepseek-r1.html
        那些生成图片，生成视频的模型和LLM有什么关系？
        chat模型 和 embedding模型 有什么区别？
        模态（modal）
            输入或输出的类型，例如 文本 文档 图片 视频 音频
            多模态（multi modal） 可以接收多种输入类型或可以输出多种类型
        局限性
            幻觉
            偏差
        什么是 多轮改写（QueryRewrite）
        什么是 重排 （rerank）
    著名的公司
        ai 四巨头
            openai 谷歌 Anthropic xai
            Anthropic 就是那个 Claude
            Anthropic 是由 openai 前员工创立的
            xai 就是 马斯克 那个 Grok
            DeepMind 就是做 AlphaGo 那个，现在是 谷歌的全资子公司
        国内的
            幻方量化/深度求索
            百度 阿里 腾讯 字节 华为 科大讯飞 月之暗面 太多了，几乎所有公司都有大模型
            四小龙
                商汤、旷视、云从、依图
            五虎？
                四小龙 + ？
    热门的大模型
        gpt 2022
        deepseek 2024
        Claude
        Grok
        Gemini
        gemma 谷歌的，Gemma是谷歌基于Gemini技术打造的轻量级模型系列
        LLaMA mate
        Phi 微软的
        BLOOM 来自法国的，也是开源的
        Mistral 来自法国的，也是开源的
        通义千问
        文心一言
        豆包 字节
        kimi 月之暗面
        混元
        星火 科大讯飞
        大模型的排行榜
            https://github.com/jeinlee1991/chinese-llm-benchmark
            https://www.superclueai.com/
            https://super.gluebenchmark.com/leaderboard
            https://lmarena.ai/leaderboard
            https://cevalbenchmark.com/static/leaderboard_zh.html
            https://llm-stats.com/
    应用
        生成文本 对话 生成视频 生成音频 视频换脸
        生成图片
            Midjourney
            DALL-E 3
            gpt4o
            文心一格
            Microsoft Designer
                DALL-E 3
            Adobe Firefly
                DALL-E 3 + Midjourney
        AI代码生成
            cursor
            Trae 也是来自字节
            MarsCode (豆包)
            文心快码
            GitHub Copilot
            通义灵码
            代码小浣熊 商汤
            CodeWhisperer 亚马逊
            CodeGeeX 智谱
    有影响力的人
        AI 三巨头
            Geoffrey Hinton：中文名是 杰弗里·辛顿
            Yann LeCun：中文名是 杨立昆
            Yoshua Bengio：中文名是 约书亚·本吉奥
        华人
            李开复
            李宏毅
            李飞飞
            吴恩达
            陆奇
            黄仁勋
            苏姿丰
            梁见后 超微电脑（Super Micro Computer） 主要是做服务器的
            梁文峰
            Alexandr Wang
        其它
            Georgi Gerganov
    相关的框架
        python的库
            Torch
            TensorFlow
                TensorFlow Lite 只能运行模型，不能用于训练模型，一般用于移动设备或边缘设备
                    TensorFlow Lite(TFLite) 现在改名成 LiteRT（Lite Runtime ）
                TensorFlow.js 是 TensorFlow 的 js 版，原本有的功能 js版基本都有
                TFX(TensorFlow Extended)
            Keras
                Keras 是用于构建和训练深度学习模型的 TensorFlow 高阶 API
            sklearn 这个主要用于学习
        ML.NET
        Apache SINGA
        Apache Spark MLlib
    相关的书籍和仓库
        Deep Learning 中文翻译 https://github.com/exacity/deeplearningbook-chinese
        深度学习500问 https://github.com/scutan90/DeepLearning-500-questions
        数学要素 https://github.com/Visualize-ML/Book3_Elements-of-Mathematics
            这是一套系列丛书，一共有七本 https://github.com/Visualize-ML/Book3_Elements-of-Mathematics/blob/main/鸢尾花书_整体布局.pdf
        如何入门人工智能科研 https://github.com/WengLean/hands-on-research-tutorial
        动手学深度学习（Dive into Deep Learning，D2L.ai） https://github.com/d2l-ai/d2l-zh
        从零开始的大语言模型原理与实践教程 https://github.com/datawhalechina/happy-llm
        21节课教你开始构建生成式AI应用所需的一切知识
            https://github.com/microsoft/generative-ai-for-beginners
            https://github.com/microsoft/generative-ai-for-beginners/blob/main/translations/zh/README.md
        ApacheCN
            https://github.com/apachecn/Interview
            https://github.com/apachecn/ailearning
            https://github.com/apachecn/ai-roadmap
        AI工具集 https://ai-bot.cn/
        多智能体框架 https://github.com/geekan/MetaGPT
        google 的机器学习教程 https://developers.google.com/machine-learning?hl=zh-cn
        tensorflow 的教程 https://www.tensorflow.org/resources/learn-ml?hl=zh-cn
    Kaggle
        这是一个类似 leetcode 的平台，题目内容是数据分析相关的
        官网 https://www.kaggle.com/
        《Python机器学习及实践：从零开始通往Kaggle竞赛之路（2022年度版）》
            https://book.douban.com/subject/36143721/
            https://github.com/godfanmiao/ML-Kaggle-Github-2022
        Kaggle 的官方入门书籍，但没有中文版
            https://github.com/PacktPublishing/The-Kaggle-Book
        ApacheCN 中对 kaggle 的介绍
            https://github.com/apachecn/Interview/tree/master/docs/Kaggle
            https://github.com/apachecn/Kaggle
    现在的人工智能缺乏可解释性，可能就像过去的微积分的无穷小一样，虽然无穷小的定义在第二次数学危机才算解决了，但是并不妨碍十七，十八，十九世纪的数学家和工程师使用微积分
    ollama
        安装
            直接从官网下载 https://ollama.com/ ，哪种系统都适用
        使用
            查看帮助 ollama --help
            拉取模型 ollama pull deepseek-r1:1.5b
            运行模型 ollama run deepseek-r1:1.5b
                模型运行后可以直接在命令行里和模型对话
            列出已存在的模型 ollama list
            启动rest服务 ollama serve
                启动rest服务后可以通过http接口和模型对话
                curl http://localhost:6399/api/generate -d '{
                    "model": "deepseek-r1:32b",
                    "prompt":"Why is the sky blue?"
                }'
            ollama 的命令和docker 很像
            可以通过修改环境变量来设置 ollama 的端口
                只修改端口 OLLAMA_PORT=8080
                修改地址和端口 OLLAMA_HOST=0.0.0.0:8080
            ollama 默认启用 OpenAI 兼容模式，也可以通过环境变量显式设置
                OLLAMA_OPENAI_COMPATIBLE=1
            ollama 的环境变量通常要在 systemd 里修改
                sudo systemctl edit ollama
        openai api
            原则上每个请求都需要在http头带上 key
                Authorization: Bearer sk-xxxxxxxx
            post 请求都要带上
                Content-Type: application/json
            遇到汉字或其它非ascii字符可能需要转换成 Unicode编码，\u9047
            {host}/v1/models
            {host}/v1/models/{model-name}
            {host}/v1/embeddings
                {
                    "model": "deepseek-r1",
                    "input": "Say somethings"
                }
            {host}/v1/completions
                {
                    "model": "deepseek-r1",
                    "prompt": "Say somethings"
                }
            {host}/v1/chat/completions
                {
                    "model": "deepseek-r1-0528",
                    "messages": [
                        {"role": "system", "content": "You are a useful assistant"},
                        {"role": "user", "content": "\u9047\u5230\u4F60\u6211\u611F\u5230\u5F88\u9AD8\u5174"}
                    ],
                    "stream": false
                }
            还有很多，但这几个最常用，兼容性也很好
            一些平台自称兼容openai api其实也就兼容这几个接口
        前端
            openwebui
            https://github.com/ollama-ui/ollama-ui
            windows 的ollama自带一个简易的ui
财政、经济、金融、股票、基金、量化
    交易 货币 贷款 存款 汇兑 股票（stocks） 债券（bonds） 外汇 期货 基金（funds）
    基础资产（Underlying Asset）
    ETF（Exchange Traded Fund）——交易型开放式指数基金
    QDII（Qualified Domestic Institutional Investor）——合格境内机构投资者
    FOF（Fund of Funds）——基金中的基金
    LOF（Listed Open-ended Fund）——上市型开放式基金
    CEF（Closed-End Fund）——封闭式基金
        中国基金法规定，开放式基金必须“可申购赎回”，封闭式基金仅限于有固定期限的封闭运作（如 3 年、5 年封闭期），到期后转开放或清算。
        中国市场上所谓的“封闭式基金”其实是定期开放式基金（如 3 年封闭期），到期后可赎回，不上市交易。
    金融衍生品/金融衍生工具
        Derivative（衍生品）
        港澳称金融衍生产品
        台湾称衍生性金融商品
        金融衍生品是以一种或多种基础资产为标的，其价值取决于这些基础资产价格或指标表现的金融合约
        什么是 标的 ？
        什么是 金融合约（Financial contracts） ？
        什么是 对冲交易 ？
        OTC
            Over The Counter （在柜台上）
            中文通常译为 “场外交易”
            源于早期股票或债券交易时，投资者直接在经纪商的柜台上进行买卖，而不是通过集中化的交易所（exchange）。
            与之相对的是 “场内交易”（Exchange-Traded），即在正规交易所进行的交易。
        四大类衍生品
            期货（futures） 期权（Options） 远期合约（Forwards） 交换（Swaps）
    现代意义的银行大概在14世纪出现
    股份制公司大概在16世纪出现
    什么是 回测
    什么是 因子挖掘
        因子（Factor） 是指能够解释资产收益差异的可量化特征
        因子挖掘（Factor Mining） 是指通过系统化的数据科学和统计方法，
        从原始数据中识别、构建和验证能够预测资产收益差异的特征变量（即“因子”）的过程。
        这些因子是量化策略的核心基础，用于构建多因子模型以获取超额收益。
        经典因子示例：
            价值因子：市盈率（PE）、市净率（PB）、股息率。
            动量因子：过去12个月收益率、短期价格趋势。
            规模因子：公司市值大小。
            质量因子：ROE（净资产收益率）、资产负债率。
        因子挖掘的核心目标 
            发现新因子：从传统数据（如财务报表、行情数据）或另类数据（如卫星图像、社交媒体情绪、供应链数据、文本新闻）中提取未被广泛认知的预测信号。
            优化现有因子：改进传统因子的计算方式（如将“市盈率”与“盈利增长”结合，构建“动态价值因子”）。
            提升策略鲁棒性：通过多因子组合降低单一因子失效的风险。
    关键指数
        大A
            上证指数
            深证
            创业
            科创50
            中证A50
            中证A500
            中证500
            中证800
            沪深300
            上证50
            深证100
            具体板块的指数？
        港股
            恒生
            国企
            恒生科技
        美股
            指标准普尔500指数（S&P 500）
            道琼斯工业平均指数（DJIA）
            纳斯达克综合指数（NASDAQ Composite）
            纳斯达克100
        其它
            黄金价格
            石油价格
            日经指数
            富时指数
    有哪些可以提供数据的网站
        新浪财经
        东方财富
        雅虎财经(Yahoo Finance)
        google财经 但数据似乎比 微软和雅虎 都要少
        同化顺
        雪球 https://xueqiu.com/stock/screener
        微软 https://www.msn.com/zh-cn/money/explorecenter
        腾讯财经 http://qt.gtimg.cn/q=sh600000 https://sqt.gtimg.cn//?q=sh000001
        openctp
            https://github.com/openctp/openctp 这个仓库里有不少接口
            http://www.openctp.cn/
            CTP （China Trading Platform 中国交易平台）
            CTP 是由上期技术（上海期货信息技术有限公司）开发的一套标准化金融交易接口
                CTP 最初由中国金融期货交易所（CFFEX）推出，主要用于期货、期权等衍生品的程序化交易。
                它提供了一套标准的 API 接口（即 CTP API），供开发者编写自动化交易程序，连接期货公司柜台系统进行行情获取、下单、撤单等操作。
                传统上，个人开发者或机构常使用“SimNow”平台提供的模拟环境来测试基于 CTP 接口的程序。
    交易所
    券商
    股票交易和分析软件
        同花顺 大智慧 指南针 东方财富 信达通 钱龙 腾讯自选股
        通达信 - 被许多民间高手和游资使用，职业交易者较为青睐
            因为最大优势就是职业抄手的通达信界面全是根据自己的看盘习惯和风格重新定制的；其次基本上所有指标都可以兼容
    同花顺都有哪些产品和服务
        电脑软件
            免费
            远航
            财富先锋
            决策先锋
            金融大师
        saas平台
            问财
            顾投平台
            量化回测 supermind https://quant.10jqka.com.cn/view/ 这个好像有新闻数据的
            量化策略平台 backtest https://backtest.10jqka.com.cn/backtest/app.html
    有哪些量化交易的平台，即使只有回测或模拟盘也可以
        www.fmz.com
        PandaAI 量化因子库
            https://www.pandaai.online/
            https://github.com/PandaAI-Tech/panda_factor
        阿布量化（ABU）
            http://www.abuquant.com/
            https://github.com/bbfamily/abu
        QUANTAXIS
            https://github.com/yutiansut/QUANTAXIS
        bigquant 的知识库 https://bigquant.com/wiki/home
    github 相关的仓库
        TradingAgents：基于多智能体大语言模型的金融交易框架 https://github.com/TauricResearch/TradingAgents
        基于多智能体LLM的中文金融交易框架 - TradingAgents中文增强版  https://github.com/hsliuping/TradingAgents-CN
        强化学习交易股票 https://github.com/sunnyswag/StockRL
        Qlib是一个面向人工智能的量化投资平台,旨在实现潜力,利用人工智能技术在定量投资中创造价值,从探索想法到实施生产。
            https://github.com/microsoft/qlib
        开源股票市场追踪与分析平台 https://github.com/Open-Dev-Society/OpenStock
        面向金融K线图的开源基础模型 https://github.com/shiyu-coder/Kronos
            可以配合 qlib 使用
        https://github.com/emcie-co/parlant
        https://github.com/stanfordnlp/dspy
excel 相关经验
    冻结单元格
    筛选
    统计公式
        求和 平均值 中位数 众数 方差 标准差 极差
    数据透视
    条件格式
    格式验证
    生成图表
    lookup/vlookup/hlookup/xlookup
        xlookup 是 excel2021 之后才有的函数
    INDEX/MATCH
    宏
    vba
    兼容性由大到小
        函数 > 宏 > vba
    格式
        xls  xcel 2003 及更低版本的默认格式
        xlsx Excel 2007 及更高版本的默认格式
        xlsm 带有宏的excel
        xltx excel模板
        xltm 带有宏的excel模板
        ods 开放文档电子表格
        ots ods的模板
        wps 的格式应该也可以打开


数据透视
    枢轴表（英语：pivot table）也翻译成透视表，是用来汇总其它表的数据。
    首先把源表分组（grouping），
    然后对各组内数据做汇总操作如排序、平均、累加、计数或字符串连接等。
    透视表用于数据处理，在数据可视化程序如电子表格或商业智能软件中常见。
    例子
        最简单的例子：
            第一张表包含一列数，透视表仅含一行一列为源表该列的均值。
        稍微复杂点的例子，
            源表有两列分别为性别与“身高”，每行给出一个人的性别与高度；
            透视表有两行两列，在“性别”列分别写“男性”与“女性”，在“身高”列分别写对应性别的平均身高。
        更为复杂与更为典型的例子，
            源表有列“月份”、“销售员”、“产品”、“销售额”，每行给出一个销售员在某个月度卖出的某种产品的金额；
            透视表第一列是“销售员”用于写其名字，其余列还有“产品名”与“总销售”用于汇总该产品在该销售人卖出的销售总额。



https://github.com/docling-project/docling
多格式文档解析和导出工具。这是一个由 IBM 开源的 Python 工具，
专门用于将各类文档转化为适合生成式 AI 使用的格式。
它能够将 PDF、DOCX、PPTX、图片、HTML、Markdown 等多种流行文档格式，
导出为 Markdown 和 JSON 格式

一个通用的文档转换工具，似乎自持很多格式
https://pandoc.org/index.html
https://github.com/jgm/pandoc

